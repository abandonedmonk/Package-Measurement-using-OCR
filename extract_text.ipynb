{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-15T11:25:46.128904Z",
     "iopub.status.busy": "2024-09-15T11:25:46.128519Z",
     "iopub.status.idle": "2024-09-15T11:26:02.070118Z",
     "shell.execute_reply": "2024-09-15T11:26:02.069095Z",
     "shell.execute_reply.started": "2024-09-15T11:25:46.128866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: easyocr in /opt/conda/lib/python3.10/site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from easyocr) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.19.0)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from easyocr) (4.10.0.84)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.14.0)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.23.2)\n",
      "Requirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.6.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.8.5.post1)\n",
      "Requirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2024.5.22)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz easyocr pandas requests pillow matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:26:02.072248Z",
     "iopub.status.busy": "2024-09-15T11:26:02.071941Z",
     "iopub.status.idle": "2024-09-15T11:26:04.782354Z",
     "shell.execute_reply": "2024-09-15T11:26:04.781407Z",
     "shell.execute_reply.started": "2024-09-15T11:26:02.072217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "E: Unable to locate package libdc1394-22-dev\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install build-essential cmake git pkg-config libgtk-3-dev \\\n",
    "    libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev \\\n",
    "    libx264-dev libjpeg-dev libpng-dev libtiff-dev gfortran openexr \\\n",
    "    libatlas-base-dev python3-dev python3-numpy libtbb2 libtbb-dev \\\n",
    "    libdc1394-22-dev libopenexr-dev libgstreamer-plugins-base1.0-dev \\\n",
    "    libgstreamer1.0-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:26:04.784005Z",
     "iopub.status.busy": "2024-09-15T11:26:04.783719Z",
     "iopub.status.idle": "2024-09-15T11:26:43.065091Z",
     "shell.execute_reply": "2024-09-15T11:26:43.063882Z",
     "shell.execute_reply.started": "2024-09-15T11:26:04.783974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'opencv'...\n",
      "remote: Enumerating objects: 336025, done.\u001b[K\n",
      "remote: Counting objects: 100% (798/798), done.\u001b[K\n",
      "remote: Compressing objects: 100% (655/655), done.\u001b[K\n",
      "remote: Total 336025 (delta 293), reused 514 (delta 120), pack-reused 335227 (from 1)\u001b[K\n",
      "Receiving objects: 100% (336025/336025), 526.16 MiB | 34.91 MiB/s, done.\n",
      "Resolving deltas: 100% (234282/234282), done.\n",
      "Updating files: 100% (7566/7566), done.\n",
      "Cloning into 'opencv_contrib'...\n",
      "remote: Enumerating objects: 41542, done.\u001b[K\n",
      "remote: Counting objects: 100% (1301/1301), done.\u001b[K\n",
      "remote: Compressing objects: 100% (938/938), done.\u001b[K\n",
      "remote: Total 41542 (delta 486), reused 911 (delta 288), pack-reused 40241 (from 1)\u001b[K\n",
      "Receiving objects: 100% (41542/41542), 149.98 MiB | 33.67 MiB/s, done.\n",
      "Resolving deltas: 100% (25618/25618), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/opencv/opencv.git\n",
    "!git clone https://github.com/opencv/opencv_contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:34:02.540345Z",
     "iopub.status.busy": "2024-09-15T11:34:02.539422Z",
     "iopub.status.idle": "2024-09-15T11:34:44.464578Z",
     "shell.execute_reply": "2024-09-15T11:34:44.463525Z",
     "shell.execute_reply.started": "2024-09-15T11:34:02.540305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/build\n",
      "cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by cmake)\n",
      "-- 'Release' build type is used by default. Use CMAKE_BUILD_TYPE to specify build type (Release or Debug)\n",
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detected processor: x86_64\n",
      "-- Found PythonInterp: /opt/conda/bin/python3 (found suitable version \"3.10.14\", minimum required is \"3.2\") \n",
      "-- Could NOT find PythonLibs (missing: PYTHON_LIBRARIES PYTHON_INCLUDE_DIRS) (Required is exact version \"3.10.14\")\n",
      "-- Looking for ccache - not found\n",
      "-- Performing Test HAVE_CXX_FSIGNED_CHAR\n",
      "-- Performing Test HAVE_CXX_FSIGNED_CHAR - Success\n",
      "-- Performing Test HAVE_C_FSIGNED_CHAR\n",
      "-- Performing Test HAVE_C_FSIGNED_CHAR - Success\n",
      "-- Performing Test HAVE_CXX_W\n",
      "-- Performing Test HAVE_CXX_W - Success\n",
      "-- Performing Test HAVE_C_W\n",
      "-- Performing Test HAVE_C_W - Success\n",
      "-- Performing Test HAVE_CXX_WALL\n",
      "-- Performing Test HAVE_CXX_WALL - Success\n",
      "-- Performing Test HAVE_C_WALL\n",
      "-- Performing Test HAVE_C_WALL - Success\n",
      "-- Performing Test HAVE_CXX_WRETURN_TYPE\n",
      "-- Performing Test HAVE_CXX_WRETURN_TYPE - Success\n",
      "-- Performing Test HAVE_C_WRETURN_TYPE\n",
      "-- Performing Test HAVE_C_WRETURN_TYPE - Success\n",
      "-- Performing Test HAVE_CXX_WNON_VIRTUAL_DTOR\n",
      "-- Performing Test HAVE_CXX_WNON_VIRTUAL_DTOR - Success\n",
      "-- Performing Test HAVE_C_WNON_VIRTUAL_DTOR\n",
      "-- Performing Test HAVE_C_WNON_VIRTUAL_DTOR - Failed\n",
      "-- Performing Test HAVE_CXX_WADDRESS\n",
      "-- Performing Test HAVE_CXX_WADDRESS - Success\n",
      "-- Performing Test HAVE_C_WADDRESS\n",
      "-- Performing Test HAVE_C_WADDRESS - Success\n",
      "-- Performing Test HAVE_CXX_WSEQUENCE_POINT\n",
      "-- Performing Test HAVE_CXX_WSEQUENCE_POINT - Success\n",
      "-- Performing Test HAVE_C_WSEQUENCE_POINT\n",
      "-- Performing Test HAVE_C_WSEQUENCE_POINT - Success\n",
      "-- Performing Test HAVE_CXX_WFORMAT\n",
      "-- Performing Test HAVE_CXX_WFORMAT - Success\n",
      "-- Performing Test HAVE_C_WFORMAT\n",
      "-- Performing Test HAVE_C_WFORMAT - Success\n",
      "-- Performing Test HAVE_CXX_WFORMAT_SECURITY\n",
      "-- Performing Test HAVE_CXX_WFORMAT_SECURITY - Success\n",
      "-- Performing Test HAVE_C_WFORMAT_SECURITY\n",
      "-- Performing Test HAVE_C_WFORMAT_SECURITY - Success\n",
      "-- Performing Test HAVE_CXX_WMISSING_DECLARATIONS\n",
      "-- Performing Test HAVE_CXX_WMISSING_DECLARATIONS - Success\n",
      "-- Performing Test HAVE_C_WMISSING_DECLARATIONS\n",
      "-- Performing Test HAVE_C_WMISSING_DECLARATIONS - Success\n",
      "-- Performing Test HAVE_CXX_WMISSING_PROTOTYPES\n",
      "-- Performing Test HAVE_CXX_WMISSING_PROTOTYPES - Failed\n",
      "-- Performing Test HAVE_C_WMISSING_PROTOTYPES\n",
      "-- Performing Test HAVE_C_WMISSING_PROTOTYPES - Success\n",
      "-- Performing Test HAVE_CXX_WSTRICT_PROTOTYPES\n",
      "-- Performing Test HAVE_CXX_WSTRICT_PROTOTYPES - Failed\n",
      "-- Performing Test HAVE_C_WSTRICT_PROTOTYPES\n",
      "-- Performing Test HAVE_C_WSTRICT_PROTOTYPES - Success\n",
      "-- Performing Test HAVE_CXX_WUNDEF\n",
      "-- Performing Test HAVE_CXX_WUNDEF - Success\n",
      "-- Performing Test HAVE_C_WUNDEF\n",
      "-- Performing Test HAVE_C_WUNDEF - Success\n",
      "-- Performing Test HAVE_CXX_WINIT_SELF\n",
      "-- Performing Test HAVE_CXX_WINIT_SELF - Success\n",
      "-- Performing Test HAVE_C_WINIT_SELF\n",
      "-- Performing Test HAVE_C_WINIT_SELF - Success\n",
      "-- Performing Test HAVE_CXX_WPOINTER_ARITH\n",
      "-- Performing Test HAVE_CXX_WPOINTER_ARITH - Success\n",
      "-- Performing Test HAVE_C_WPOINTER_ARITH\n",
      "-- Performing Test HAVE_C_WPOINTER_ARITH - Success\n",
      "-- Performing Test HAVE_CXX_WSHADOW\n",
      "-- Performing Test HAVE_CXX_WSHADOW - Success\n",
      "-- Performing Test HAVE_C_WSHADOW\n",
      "-- Performing Test HAVE_C_WSHADOW - Success\n",
      "-- Performing Test HAVE_CXX_WSIGN_PROMO\n",
      "-- Performing Test HAVE_CXX_WSIGN_PROMO - Success\n",
      "-- Performing Test HAVE_C_WSIGN_PROMO\n",
      "-- Performing Test HAVE_C_WSIGN_PROMO - Failed\n",
      "-- Performing Test HAVE_CXX_WUNINITIALIZED\n",
      "-- Performing Test HAVE_CXX_WUNINITIALIZED - Success\n",
      "-- Performing Test HAVE_C_WUNINITIALIZED\n",
      "-- Performing Test HAVE_C_WUNINITIALIZED - Success\n",
      "-- Performing Test HAVE_CXX_WSUGGEST_OVERRIDE\n",
      "-- Performing Test HAVE_CXX_WSUGGEST_OVERRIDE - Success\n",
      "-- Performing Test HAVE_C_WSUGGEST_OVERRIDE\n",
      "-- Performing Test HAVE_C_WSUGGEST_OVERRIDE - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_DELETE_NON_VIRTUAL_DTOR\n",
      "-- Performing Test HAVE_CXX_WNO_DELETE_NON_VIRTUAL_DTOR - Success\n",
      "-- Performing Test HAVE_C_WNO_DELETE_NON_VIRTUAL_DTOR\n",
      "-- Performing Test HAVE_C_WNO_DELETE_NON_VIRTUAL_DTOR - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_UNNAMED_TYPE_TEMPLATE_ARGS\n",
      "-- Performing Test HAVE_CXX_WNO_UNNAMED_TYPE_TEMPLATE_ARGS - Failed\n",
      "-- Performing Test HAVE_C_WNO_UNNAMED_TYPE_TEMPLATE_ARGS\n",
      "-- Performing Test HAVE_C_WNO_UNNAMED_TYPE_TEMPLATE_ARGS - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_COMMENT\n",
      "-- Performing Test HAVE_CXX_WNO_COMMENT - Success\n",
      "-- Performing Test HAVE_C_WNO_COMMENT\n",
      "-- Performing Test HAVE_C_WNO_COMMENT - Success\n",
      "-- Performing Test HAVE_CXX_WIMPLICIT_FALLTHROUGH_3\n",
      "-- Performing Test HAVE_CXX_WIMPLICIT_FALLTHROUGH_3 - Success\n",
      "-- Performing Test HAVE_C_WIMPLICIT_FALLTHROUGH_3\n",
      "-- Performing Test HAVE_C_WIMPLICIT_FALLTHROUGH_3 - Success\n",
      "-- Performing Test HAVE_CXX_WNO_STRICT_OVERFLOW\n",
      "-- Performing Test HAVE_CXX_WNO_STRICT_OVERFLOW - Success\n",
      "-- Performing Test HAVE_C_WNO_STRICT_OVERFLOW\n",
      "-- Performing Test HAVE_C_WNO_STRICT_OVERFLOW - Success\n",
      "-- Performing Test HAVE_CXX_FDIAGNOSTICS_SHOW_OPTION\n",
      "-- Performing Test HAVE_CXX_FDIAGNOSTICS_SHOW_OPTION - Success\n",
      "-- Performing Test HAVE_C_FDIAGNOSTICS_SHOW_OPTION\n",
      "-- Performing Test HAVE_C_FDIAGNOSTICS_SHOW_OPTION - Success\n",
      "-- Performing Test HAVE_CXX_WNO_LONG_LONG\n",
      "-- Performing Test HAVE_CXX_WNO_LONG_LONG - Success\n",
      "-- Performing Test HAVE_C_WNO_LONG_LONG\n",
      "-- Performing Test HAVE_C_WNO_LONG_LONG - Success\n",
      "-- Performing Test HAVE_CXX_PTHREAD\n",
      "-- Performing Test HAVE_CXX_PTHREAD - Success\n",
      "-- Performing Test HAVE_C_PTHREAD\n",
      "-- Performing Test HAVE_C_PTHREAD - Success\n",
      "-- Performing Test HAVE_CXX_FOMIT_FRAME_POINTER\n",
      "-- Performing Test HAVE_CXX_FOMIT_FRAME_POINTER - Success\n",
      "-- Performing Test HAVE_C_FOMIT_FRAME_POINTER\n",
      "-- Performing Test HAVE_C_FOMIT_FRAME_POINTER - Success\n",
      "-- Performing Test HAVE_CXX_FFUNCTION_SECTIONS\n",
      "-- Performing Test HAVE_CXX_FFUNCTION_SECTIONS - Success\n",
      "-- Performing Test HAVE_C_FFUNCTION_SECTIONS\n",
      "-- Performing Test HAVE_C_FFUNCTION_SECTIONS - Success\n",
      "-- Performing Test HAVE_CXX_FDATA_SECTIONS\n",
      "-- Performing Test HAVE_CXX_FDATA_SECTIONS - Success\n",
      "-- Performing Test HAVE_C_FDATA_SECTIONS\n",
      "-- Performing Test HAVE_C_FDATA_SECTIONS - Success\n",
      "-- Performing Test HAVE_CPU_SSE_SUPPORT (check file: cmake/checks/cpu_sse.cpp)\n",
      "-- Performing Test HAVE_CPU_SSE_SUPPORT - Success\n",
      "-- Performing Test HAVE_CPU_SSE2_SUPPORT (check file: cmake/checks/cpu_sse2.cpp)\n",
      "-- Performing Test HAVE_CPU_SSE2_SUPPORT - Success\n",
      "-- Performing Test HAVE_CPU_SSE3_SUPPORT (check file: cmake/checks/cpu_sse3.cpp)\n",
      "-- Performing Test HAVE_CPU_SSE3_SUPPORT - Failed\n",
      "-- Performing Test HAVE_CXX_MSSE3 (check file: cmake/checks/cpu_sse3.cpp)\n",
      "-- Performing Test HAVE_CXX_MSSE3 - Success\n",
      "-- Performing Test HAVE_CXX_MSSSE3 (check file: cmake/checks/cpu_ssse3.cpp)\n",
      "-- Performing Test HAVE_CXX_MSSSE3 - Success\n",
      "-- Performing Test HAVE_CXX_MSSE4_1 (check file: cmake/checks/cpu_sse41.cpp)\n",
      "-- Performing Test HAVE_CXX_MSSE4_1 - Success\n",
      "-- Performing Test HAVE_CXX_MPOPCNT (check file: cmake/checks/cpu_popcnt.cpp)\n",
      "-- Performing Test HAVE_CXX_MPOPCNT - Success\n",
      "-- Performing Test HAVE_CXX_MSSE4_2 (check file: cmake/checks/cpu_sse42.cpp)\n",
      "-- Performing Test HAVE_CXX_MSSE4_2 - Success\n",
      "-- Performing Test HAVE_CXX_MAVX (check file: cmake/checks/cpu_avx.cpp)\n",
      "-- Performing Test HAVE_CXX_MAVX - Success\n",
      "-- Performing Test HAVE_CXX_MF16C (check file: cmake/checks/cpu_fp16.cpp)\n",
      "-- Performing Test HAVE_CXX_MF16C - Success\n",
      "-- Performing Test HAVE_CXX_MAVX2 (check file: cmake/checks/cpu_avx2.cpp)\n",
      "-- Performing Test HAVE_CXX_MAVX2 - Success\n",
      "-- Performing Test HAVE_CXX_MFMA\n",
      "-- Performing Test HAVE_CXX_MFMA - Success\n",
      "-- Performing Test HAVE_CXX_MAVX512F (check file: cmake/checks/cpu_avx512.cpp)\n",
      "-- Performing Test HAVE_CXX_MAVX512F - Success\n",
      "-- Performing Test HAVE_CXX_MAVX512F_MAVX512CD (check file: cmake/checks/cpu_avx512common.cpp)\n",
      "-- Performing Test HAVE_CXX_MAVX512F_MAVX512CD - Success\n",
      "-- Performing Test HAVE_CXX_MAVX512F_MAVX512CD_MAVX512VL_MAVX512BW_MAVX512DQ (check file: cmake/checks/cpu_avx512skx.cpp)\n",
      "-- Performing Test HAVE_CXX_MAVX512F_MAVX512CD_MAVX512VL_MAVX512BW_MAVX512DQ - Success\n",
      "-- Performing Test HAVE_CPU_BASELINE_FLAGS\n",
      "-- Performing Test HAVE_CPU_BASELINE_FLAGS - Success\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_SSE4_1\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_SSE4_1 - Success\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_SSE4_2\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_SSE4_2 - Success\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_AVX\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_AVX - Success\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_FP16\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_FP16 - Success\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_AVX2\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_AVX2 - Success\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_AVX512_SKX\n",
      "-- Performing Test HAVE_CPU_DISPATCH_FLAGS_AVX512_SKX - Success\n",
      "-- Performing Test HAVE_CXX_FVISIBILITY_HIDDEN\n",
      "-- Performing Test HAVE_CXX_FVISIBILITY_HIDDEN - Success\n",
      "-- Performing Test HAVE_C_FVISIBILITY_HIDDEN\n",
      "-- Performing Test HAVE_C_FVISIBILITY_HIDDEN - Success\n",
      "-- Performing Test HAVE_CXX_FVISIBILITY_INLINES_HIDDEN\n",
      "-- Performing Test HAVE_CXX_FVISIBILITY_INLINES_HIDDEN - Success\n",
      "-- Performing Test HAVE_C_FVISIBILITY_INLINES_HIDDEN\n",
      "-- Performing Test HAVE_C_FVISIBILITY_INLINES_HIDDEN - Failed\n",
      "-- Performing Test HAVE_LINK_AS_NEEDED\n",
      "-- Performing Test HAVE_LINK_AS_NEEDED - Success\n",
      "-- Performing Test HAVE_LINK_NO_UNDEFINED\n",
      "-- Performing Test HAVE_LINK_NO_UNDEFINED - Success\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for posix_memalign\n",
      "-- Looking for posix_memalign - found\n",
      "-- Looking for malloc.h\n",
      "-- Looking for malloc.h - found\n",
      "-- Looking for memalign\n",
      "-- Looking for memalign - found\n",
      "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found suitable version \"1.2.11\", minimum required is \"1.2.3\") \n",
      "-- Found JPEG: /usr/lib/x86_64-linux-gnu/libjpeg.so (found version \"80\") \n",
      "-- Could NOT find TIFF (missing: TIFF_LIBRARY TIFF_INCLUDE_DIR) \n",
      "-- Looking for assert.h\n",
      "-- Looking for assert.h - found\n",
      "-- Looking for dlfcn.h\n",
      "-- Looking for dlfcn.h - found\n",
      "-- Looking for fcntl.h\n",
      "-- Looking for fcntl.h - found\n",
      "-- Looking for inttypes.h\n",
      "-- Looking for inttypes.h - found\n",
      "-- Looking for io.h\n",
      "-- Looking for io.h - not found\n",
      "-- Looking for limits.h\n",
      "-- Looking for limits.h - found\n",
      "-- Looking for memory.h\n",
      "-- Looking for memory.h - found\n",
      "-- Looking for search.h\n",
      "-- Looking for search.h - found\n",
      "-- Looking for stdint.h\n",
      "-- Looking for stdint.h - found\n",
      "-- Looking for string.h\n",
      "-- Looking for string.h - found\n",
      "-- Looking for strings.h\n",
      "-- Looking for strings.h - found\n",
      "-- Looking for sys/time.h\n",
      "-- Looking for sys/time.h - found\n",
      "-- Looking for sys/types.h\n",
      "-- Looking for sys/types.h - found\n",
      "-- Looking for unistd.h\n",
      "-- Looking for unistd.h - found\n",
      "-- Performing Test C_HAS_inline\n",
      "-- Performing Test C_HAS_inline - Success\n",
      "-- Looking for stddef.h\n",
      "-- Looking for stddef.h - found\n",
      "-- Check size of signed short\n",
      "-- Check size of signed short - done\n",
      "-- Check size of unsigned short\n",
      "-- Check size of unsigned short - done\n",
      "-- Check size of signed int\n",
      "-- Check size of signed int - done\n",
      "-- Check size of unsigned int\n",
      "-- Check size of unsigned int - done\n",
      "-- Check size of signed long\n",
      "-- Check size of signed long - done\n",
      "-- Check size of unsigned long\n",
      "-- Check size of unsigned long - done\n",
      "-- Check size of signed long long\n",
      "-- Check size of signed long long - done\n",
      "-- Check size of unsigned long long\n",
      "-- Check size of unsigned long long - done\n",
      "-- Check size of unsigned char *\n",
      "-- Check size of unsigned char * - done\n",
      "-- Check size of size_t\n",
      "-- Check size of size_t - done\n",
      "-- Check size of ptrdiff_t\n",
      "-- Check size of ptrdiff_t - done\n",
      "-- Check size of INT8\n",
      "-- Check size of INT8 - failed\n",
      "-- Check size of INT16\n",
      "-- Check size of INT16 - failed\n",
      "-- Check size of INT32\n",
      "-- Check size of INT32 - failed\n",
      "-- Looking for floor\n",
      "-- Looking for floor - found\n",
      "-- Looking for pow\n",
      "-- Looking for pow - found\n",
      "-- Looking for sqrt\n",
      "-- Looking for sqrt - found\n",
      "-- Looking for isascii\n",
      "-- Looking for isascii - found\n",
      "-- Looking for memset\n",
      "-- Looking for memset - found\n",
      "-- Looking for mmap\n",
      "-- Looking for mmap - found\n",
      "-- Looking for getopt\n",
      "-- Looking for getopt - found\n",
      "-- Looking for memmove\n",
      "-- Looking for memmove - found\n",
      "-- Looking for setmode\n",
      "-- Looking for setmode - not found\n",
      "-- Looking for strcasecmp\n",
      "-- Looking for strcasecmp - found\n",
      "-- Looking for strchr\n",
      "-- Looking for strchr - found\n",
      "-- Looking for strrchr\n",
      "-- Looking for strrchr - found\n",
      "-- Looking for strstr\n",
      "-- Looking for strstr - found\n",
      "-- Looking for strtol\n",
      "-- Looking for strtol - found\n",
      "-- Looking for strtol\n",
      "-- Looking for strtol - found\n",
      "-- Looking for strtoull\n",
      "-- Looking for strtoull - found\n",
      "-- Looking for lfind\n",
      "-- Looking for lfind - found\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_BUT_SET_VARIABLE\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_BUT_SET_VARIABLE - Success\n",
      "-- Performing Test HAVE_C_WNO_MISSING_PROTOTYPES\n",
      "-- Performing Test HAVE_C_WNO_MISSING_PROTOTYPES - Success\n",
      "-- Performing Test HAVE_C_WNO_MISSING_DECLARATIONS\n",
      "-- Performing Test HAVE_C_WNO_MISSING_DECLARATIONS - Success\n",
      "-- Performing Test HAVE_C_WNO_UNDEF\n",
      "-- Performing Test HAVE_C_WNO_UNDEF - Success\n",
      "-- Performing Test HAVE_C_WNO_UNUSED\n",
      "-- Performing Test HAVE_C_WNO_UNUSED - Success\n",
      "-- Performing Test HAVE_C_WNO_SIGN_COMPARE\n",
      "-- Performing Test HAVE_C_WNO_SIGN_COMPARE - Success\n",
      "-- Performing Test HAVE_C_WNO_CAST_ALIGN\n",
      "-- Performing Test HAVE_C_WNO_CAST_ALIGN - Success\n",
      "-- Performing Test HAVE_C_WNO_SHADOW\n",
      "-- Performing Test HAVE_C_WNO_SHADOW - Success\n",
      "-- Performing Test HAVE_C_WNO_MAYBE_UNINITIALIZED\n",
      "-- Performing Test HAVE_C_WNO_MAYBE_UNINITIALIZED - Success\n",
      "-- Performing Test HAVE_C_WNO_POINTER_TO_INT_CAST\n",
      "-- Performing Test HAVE_C_WNO_POINTER_TO_INT_CAST - Success\n",
      "-- Performing Test HAVE_C_WNO_INT_TO_POINTER_CAST\n",
      "-- Performing Test HAVE_C_WNO_INT_TO_POINTER_CAST - Success\n",
      "-- Performing Test HAVE_C_WNO_MISLEADING_INDENTATION\n",
      "-- Performing Test HAVE_C_WNO_MISLEADING_INDENTATION - Success\n",
      "-- Performing Test HAVE_C_WNO_IMPLICIT_FALLTHROUGH\n",
      "-- Performing Test HAVE_C_WNO_IMPLICIT_FALLTHROUGH - Success\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_PARAMETER\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_PARAMETER - Success\n",
      "-- Performing Test HAVE_C_WNO_ARRAY_PARAMETER\n",
      "-- Performing Test HAVE_C_WNO_ARRAY_PARAMETER - Success\n",
      "-- Performing Test HAVE_C_WNO_STRICT_PROTOTYPES\n",
      "-- Performing Test HAVE_C_WNO_STRICT_PROTOTYPES - Success\n",
      "-- Performing Test HAVE_CXX_WNO_MISSING_DECLARATIONS\n",
      "-- Performing Test HAVE_CXX_WNO_MISSING_DECLARATIONS - Success\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_PARAMETER\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_PARAMETER - Success\n",
      "-- Performing Test HAVE_CXX_WNO_MISSING_PROTOTYPES\n",
      "-- Performing Test HAVE_CXX_WNO_MISSING_PROTOTYPES - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_UNDEF\n",
      "-- Performing Test HAVE_CXX_WNO_UNDEF - Success\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_VARIABLE\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_VARIABLE - Success\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_FUNCTION\n",
      "-- Performing Test HAVE_C_WNO_UNUSED_FUNCTION - Success\n",
      "-- Found system OpenJPEG: openjp2 (found version \"2.5.2\")\n",
      "-- libva: missing va.h header (VA_INCLUDE_DIR)\n",
      "-- IPPICV: Downloading ippicv_2021.12.0_lnx_intel64_20240425_general.tgz from https://raw.githubusercontent.com/opencv/opencv_3rdparty/7f55c0c26be418d494615afca15218566775c725/ippicv/ippicv_2021.12.0_lnx_intel64_20240425_general.tgz\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- found Intel IPP (ICV version): 2021.12.0 [2021.12.0]\n",
      "-- at: /kaggle/working/build/3rdparty/ippicv/ippicv_lnx/icv\n",
      "-- found Intel IPP Integration Wrappers sources: 2021.12.0\n",
      "-- at: /kaggle/working/build/3rdparty/ippicv/ippicv_lnx/iw\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so (found suitable version \"9.0.0\", minimum required is \"7.5\") \n",
      "-- NVCUVID: Header not found, WITH_NVCUVID requires Nvidia decoding library header /opt/conda/targets/x86_64-linux;/opt/conda/targets/x86_64-linux/include/nvcuvid.h\n",
      "-- NVCUVENC: Header not found, WITH_NVCUVENC requires Nvidia encoding library header /opt/conda/targets/x86_64-linux;/opt/conda/targets/x86_64-linux/include/nvEncodeAPI.h\n",
      "-- CUDA detected: 12.3\n",
      "\u001b[33mCMake Warning at cmake/OpenCVDetectCUDAUtils.cmake:187 (message):\n",
      "  CUDA: Autodetection arch list is empty.  Please enable\n",
      "  OPENCV_CMAKE_CUDA_DEBUG=1 and check/specify\n",
      "  OPENCV_CUDA_DETECTION_NVCC_FLAGS variable\n",
      "Call Stack (most recent call first):\n",
      "  cmake/OpenCVDetectCUDAUtils.cmake:286 (ocv_filter_available_architecture)\n",
      "  cmake/OpenCVDetectCUDA.cmake:76 (ocv_set_cuda_arch_bin_and_ptx)\n",
      "  cmake/OpenCVFindLibsPerf.cmake:46 (include)\n",
      "  CMakeLists.txt:787 (include)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at cmake/OpenCVDetectCUDAUtils.cmake:297 (list):\n",
      "  list GET given empty list\n",
      "Call Stack (most recent call first):\n",
      "  cmake/OpenCVDetectCUDA.cmake:76 (ocv_set_cuda_arch_bin_and_ptx)\n",
      "  cmake/OpenCVFindLibsPerf.cmake:46 (include)\n",
      "  CMakeLists.txt:787 (include)\n",
      "\n",
      "\u001b[0m\n",
      "-- CUDA: NVCC target flags -D_FORCE_INLINES\n",
      "-- Could not find OpenBLAS include. Turning OpenBLAS_FOUND off\n",
      "-- Could not find OpenBLAS lib. Turning OpenBLAS_FOUND off\n",
      "-- Could NOT find Atlas (missing: Atlas_CBLAS_INCLUDE_DIR Atlas_CLAPACK_INCLUDE_DIR Atlas_CBLAS_LIBRARY Atlas_BLAS_LIBRARY Atlas_LAPACK_LIBRARY) \n",
      "-- Looking for sgemm_\n",
      "-- Looking for sgemm_ - not found\n",
      "-- Looking for sgemm_\n",
      "-- Looking for sgemm_ - found\n",
      "-- Found BLAS: /opt/conda/lib/libmkl_intel_lp64.so;/opt/conda/lib/libmkl_intel_thread.so;/opt/conda/lib/libmkl_core.so;/opt/conda/lib/libiomp5.so;-lm;-ldl  \n",
      "-- Looking for cheev_\n",
      "-- Looking for cheev_ - found\n",
      "-- Found LAPACK: /opt/conda/lib/libmkl_intel_lp64.so;/opt/conda/lib/libmkl_intel_thread.so;/opt/conda/lib/libmkl_core.so;/opt/conda/lib/libiomp5.so;-lm;-ldl;-lm;-ldl  \n",
      "-- Performing Test HAVE_CXX_WNO_DEPRECATED\n",
      "-- Performing Test HAVE_CXX_WNO_DEPRECATED - Success\n",
      "-- Performing Test HAVE_CXX_WNO_SHADOW\n",
      "-- Performing Test HAVE_CXX_WNO_SHADOW - Success\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_LOCAL_TYPEDEFS\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_LOCAL_TYPEDEFS - Success\n",
      "-- Performing Test HAVE_CXX_WNO_SIGN_COMPARE\n",
      "-- Performing Test HAVE_CXX_WNO_SIGN_COMPARE - Success\n",
      "-- Performing Test HAVE_CXX_WNO_SIGN_PROMO\n",
      "-- Performing Test HAVE_CXX_WNO_SIGN_PROMO - Success\n",
      "-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_UNDEFINED_COMPARE\n",
      "-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_UNDEFINED_COMPARE - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_IGNORED_QUALIFIERS\n",
      "-- Performing Test HAVE_CXX_WNO_IGNORED_QUALIFIERS - Success\n",
      "-- Performing Test HAVE_CXX_WNO_EXTRA\n",
      "-- Performing Test HAVE_CXX_WNO_EXTRA - Success\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_FUNCTION\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_FUNCTION - Success\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_CONST_VARIABLE\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_CONST_VARIABLE - Success\n",
      "-- Performing Test HAVE_CXX_WNO_SHORTEN_64_TO_32\n",
      "-- Performing Test HAVE_CXX_WNO_SHORTEN_64_TO_32 - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_INVALID_OFFSETOF\n",
      "-- Performing Test HAVE_CXX_WNO_INVALID_OFFSETOF - Success\n",
      "-- Performing Test HAVE_CXX_WNO_ENUM_COMPARE_SWITCH\n",
      "-- Performing Test HAVE_CXX_WNO_ENUM_COMPARE_SWITCH - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_SUGGEST_OVERRIDE\n",
      "-- Performing Test HAVE_CXX_WNO_SUGGEST_OVERRIDE - Success\n",
      "-- Performing Test HAVE_CXX_WNO_INCONSISTENT_MISSING_OVERRIDE\n",
      "-- Performing Test HAVE_CXX_WNO_INCONSISTENT_MISSING_OVERRIDE - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_IMPLICIT_FALLTHROUGH\n",
      "-- Performing Test HAVE_CXX_WNO_IMPLICIT_FALLTHROUGH - Success\n",
      "-- Performing Test HAVE_CXX_WNO_ARRAY_BOUNDS\n",
      "-- Performing Test HAVE_CXX_WNO_ARRAY_BOUNDS - Success\n",
      "-- Performing Test HAVE_CXX_WNO_STRINGOP_OVERFLOW\n",
      "-- Performing Test HAVE_CXX_WNO_STRINGOP_OVERFLOW - Success\n",
      "-- Performing Test HAVE_CXX_WNO_STRINGOP_OVERREAD\n",
      "-- Performing Test HAVE_CXX_WNO_STRINGOP_OVERREAD - Success\n",
      "-- Performing Test HAVE_CXX_WNO_EXTRA_SEMI\n",
      "-- Performing Test HAVE_CXX_WNO_EXTRA_SEMI - Success\n",
      "-- Performing Test HAVE_CXX_WNO_COMMA\n",
      "-- Performing Test HAVE_CXX_WNO_COMMA - Failed\n",
      "-- Performing Test HAVE_CXX_WNO_CLASS_MEMACCESS\n",
      "-- Performing Test HAVE_CXX_WNO_CLASS_MEMACCESS - Success\n",
      "-- Could NOT find Java (missing: Java_JAR_EXECUTABLE Java_JAVAC_EXECUTABLE Java_JAVADOC_EXECUTABLE) (found version \"11.0.24\")\n",
      "-- Could NOT find JNI (missing: JAVA_INCLUDE_PATH JAVA_INCLUDE_PATH2 JAVA_AWT_INCLUDE_PATH) \n",
      "-- VTK is not found. Please set -DVTK_DIR in CMake to VTK build directory, or to VTK install subdirectory with VTKConfig.cmake file\n",
      "-- Looking for dlerror in dl\n",
      "-- Looking for dlerror in dl - found\n",
      "-- ADE: Downloading v0.1.2d.zip from https://github.com/opencv/ade/archive/v0.1.2d.zip\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- Checking for module 'gtk+-3.0'\n",
      "--   No package 'gtk+-3.0' found\n",
      "-- Checking for module 'gtk+-2.0'\n",
      "--   Found gtk+-2.0, version 2.24.33\n",
      "\u001b[33mCMake Warning at cmake/OpenCVUtils.cmake:889 (message):\n",
      "  ocv_check_modules(GTK2): can't find library 'gio-2.0'.  Specify\n",
      "  'pkgcfg_lib_GTK2_gio-2.0' manually\n",
      "Call Stack (most recent call first):\n",
      "  modules/highgui/cmake/detect_gtk.cmake:12 (ocv_check_modules)\n",
      "  modules/highgui/cmake/init.cmake:35 (include)\n",
      "  modules/highgui/cmake/init.cmake:39 (add_backend)\n",
      "  cmake/OpenCVModule.cmake:298 (include)\n",
      "  cmake/OpenCVModule.cmake:361 (_add_modules_1)\n",
      "  cmake/OpenCVModule.cmake:408 (ocv_glob_modules)\n",
      "  CMakeLists.txt:1040 (ocv_register_modules)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33mCMake Warning at cmake/OpenCVUtils.cmake:889 (message):\n",
      "  ocv_check_modules(GTK2): can't find library 'gobject-2.0'.  Specify\n",
      "  'pkgcfg_lib_GTK2_gobject-2.0' manually\n",
      "Call Stack (most recent call first):\n",
      "  modules/highgui/cmake/detect_gtk.cmake:12 (ocv_check_modules)\n",
      "  modules/highgui/cmake/init.cmake:35 (include)\n",
      "  modules/highgui/cmake/init.cmake:39 (add_backend)\n",
      "  cmake/OpenCVModule.cmake:298 (include)\n",
      "  cmake/OpenCVModule.cmake:361 (_add_modules_1)\n",
      "  cmake/OpenCVModule.cmake:408 (ocv_glob_modules)\n",
      "  CMakeLists.txt:1040 (ocv_register_modules)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33mCMake Warning at cmake/OpenCVUtils.cmake:889 (message):\n",
      "  ocv_check_modules(GTK2): can't find library 'glib-2.0'.  Specify\n",
      "  'pkgcfg_lib_GTK2_glib-2.0' manually\n",
      "Call Stack (most recent call first):\n",
      "  modules/highgui/cmake/detect_gtk.cmake:12 (ocv_check_modules)\n",
      "  modules/highgui/cmake/init.cmake:35 (include)\n",
      "  modules/highgui/cmake/init.cmake:39 (add_backend)\n",
      "  cmake/OpenCVModule.cmake:298 (include)\n",
      "  cmake/OpenCVModule.cmake:361 (_add_modules_1)\n",
      "  cmake/OpenCVModule.cmake:408 (ocv_glob_modules)\n",
      "  CMakeLists.txt:1040 (ocv_register_modules)\n",
      "\n",
      "\u001b[0m\n",
      "-- Performing Test HAVE_CXX_WNO_STRICT_ALIASING\n",
      "-- Performing Test HAVE_CXX_WNO_STRICT_ALIASING - Success\n",
      "-- Checking for modules 'libavcodec;libavformat;libavutil;libswscale'\n",
      "--   No package 'libavcodec' found\n",
      "--   No package 'libavformat' found\n",
      "--   No package 'libavutil' found\n",
      "--   No package 'libswscale' found\n",
      "-- FFMPEG is disabled. Required libraries: libavcodec;libavformat;libavutil;libswscale. Missing libraries: libavcodec;libavformat;libavutil;libswscale\n",
      "-- Checking for module 'gstreamer-base-1.0'\n",
      "--   No package 'gstreamer-base-1.0' found\n",
      "-- Checking for module 'gstreamer-app-1.0'\n",
      "--   No package 'gstreamer-app-1.0' found\n",
      "-- Checking for module 'gstreamer-riff-1.0'\n",
      "--   No package 'gstreamer-riff-1.0' found\n",
      "-- Checking for module 'gstreamer-pbutils-1.0'\n",
      "--   No package 'gstreamer-pbutils-1.0' found\n",
      "-- Checking for module 'gstreamer-video-1.0'\n",
      "--   No package 'gstreamer-video-1.0' found\n",
      "-- Checking for module 'gstreamer-audio-1.0'\n",
      "--   No package 'gstreamer-audio-1.0' found\n",
      "-- Module opencv_alphamat disabled because the following dependencies are not found: Eigen\n",
      "-- Performing Test HAVE_CXX_WNO_ENUM_COMPARE\n",
      "-- Performing Test HAVE_CXX_WNO_ENUM_COMPARE - Success\n",
      "-- Performing Test HAVE_CXX_WNO_UNINITIALIZED\n",
      "-- Performing Test HAVE_CXX_WNO_UNINITIALIZED - Success\n",
      "-- Performing Test HAVE_CXX_WNO_DEPRECATED_DECLARATIONS\n",
      "-- Performing Test HAVE_CXX_WNO_DEPRECATED_DECLARATIONS - Success\n",
      "-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_COMPARE\n",
      "-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_COMPARE - Success\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_VARIABLE\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_VARIABLE - Success\n",
      "-- Checking for module 'freetype2'\n",
      "--   Found freetype2, version 24.3.18\n",
      "-- Checking for module 'harfbuzz'\n",
      "--   Found harfbuzz, version 9.0.0\n",
      "-- freetype2:   YES (ver 24.3.18)\n",
      "-- harfbuzz:    YES (ver 9.0.0)\n",
      "-- Found HDF5: /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so;/usr/lib/x86_64-linux-gnu/libcrypto.so;/usr/lib/x86_64-linux-gnu/libcurl.so;/usr/lib/x86_64-linux-gnu/libpthread.a;/usr/lib/x86_64-linux-gnu/libsz.so;/usr/lib/x86_64-linux-gnu/libz.so;/usr/lib/x86_64-linux-gnu/libdl.a;/usr/lib/x86_64-linux-gnu/libm.so (found version \"1.10.7\")  \n",
      "-- Julia not found. Not compiling Julia Bindings. \n",
      "-- Module opencv_ovis disabled because OGRE3D was not found\n",
      "-- Checking SFM glog/gflags deps... TRUE\n",
      "-- Module opencv_sfm disabled because the following dependencies are not found: Eigen\n",
      "-- Checking for module 'tesseract'\n",
      "--   No package 'tesseract' found\n",
      "-- Tesseract:   NO\n",
      "-- Allocator metrics storage type: 'long long'\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_BUT_SET_VARIABLE\n",
      "-- Performing Test HAVE_CXX_WNO_UNUSED_BUT_SET_VARIABLE - Success\n",
      "-- Excluding from source files list: modules/imgproc/src/imgwarp.lasx.cpp\n",
      "-- Excluding from source files list: modules/imgproc/src/resize.lasx.cpp\n",
      "-- Registering hook 'INIT_MODULE_SOURCES_opencv_dnn': /kaggle/working/opencv/modules/dnn/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake\n",
      "-- Excluding from source files list: modules/dnn/src/layers/cpu_kernels/conv_winograd_f63.neon.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/layers_common.rvv.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/layers_common.lasx.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/int8layers/layers_common.rvv.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/int8layers/layers_common.lasx.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_block.neon.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_block.neon_fp16.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_depthwise.rvv.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_depthwise.lasx.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_winograd_f63.neon_fp16.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/fast_gemm_kernels.neon.cpp\n",
      "-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/fast_gemm_kernels.lasx.cpp\n",
      "-- Performing Test HAVE_CXX_WNO_OVERLOADED_VIRTUAL\n",
      "-- Performing Test HAVE_CXX_WNO_OVERLOADED_VIRTUAL - Success\n",
      "\u001b[33mCMake Warning at /kaggle/working/opencv_contrib/modules/cudacodec/CMakeLists.txt:26 (message):\n",
      "  cudacodec::VideoReader requires Nvidia Video Codec SDK.  Please resolve\n",
      "  dependency or disable WITH_NVCUVID=OFF\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33mCMake Warning at /kaggle/working/opencv_contrib/modules/cudacodec/CMakeLists.txt:30 (message):\n",
      "  cudacodec::VideoWriter requires Nvidia Video Codec SDK.  Please resolve\n",
      "  dependency or disable WITH_NVCUVENC=OFF\n",
      "\n",
      "\u001b[0m\n",
      "-- highgui: using builtin backend: GTK2\n",
      "-- rgbd: Eigen support is disabled. Eigen is Required for Posegraph optimization\n",
      "-- Performing Test Iconv_IS_BUILT_IN\n",
      "-- Performing Test Iconv_IS_BUILT_IN - Success\n",
      "-- wechat_qrcode: Downloading detect.caffemodel from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/detect.caffemodel\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- wechat_qrcode: Downloading detect.prototxt from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/detect.prototxt\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- wechat_qrcode: Downloading sr.caffemodel from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/sr.caffemodel\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- wechat_qrcode: Downloading sr.prototxt from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/sr.prototxt\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_bgm.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_bgm_bi.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm_bi.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_bgm_hd.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm_hd.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_binboost_064.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_064.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_binboost_128.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_128.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_binboost_256.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_256.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/boostdesc: Downloading boostdesc_lbgm.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_lbgm.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/vgg: Downloading vgg_generated_48.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_48.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/vgg: Downloading vgg_generated_64.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_64.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/vgg: Downloading vgg_generated_80.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_80.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- xfeatures2d/vgg: Downloading vgg_generated_120.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_120.i\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- data: Downloading face_landmark_model.dat from https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- Use autogenerated whitelist /kaggle/working/build/modules/js_bindings_generator/whitelist.json\n",
      "-- NVIDIA_OPTICAL_FLOW: Downloading edb50da3cf849840d680249aa6dbef248ebce2ca.zip from https://github.com/NVIDIA/NVIDIAOpticalFlowSDK/archive/edb50da3cf849840d680249aa6dbef248ebce2ca.zip\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- Building with NVIDIA Optical Flow API 2.0\n",
      "-- Found 'misc' Python modules from /kaggle/working/opencv/modules/python/package/extra_modules\n",
      "-- Found 'mat_wrapper;utils' Python modules from /kaggle/working/opencv/modules/core/misc/python/package\n",
      "-- Found 'gapi' Python modules from /kaggle/working/opencv/modules/gapi/misc/python/package\n",
      "-- \n",
      "-- General configuration for OpenCV 4.10.0-dev =====================================\n",
      "--   Version control:               4.10.0-281-ge1fec15627\n",
      "-- \n",
      "--   Extra modules:\n",
      "--     Location (extra):            /kaggle/working/opencv_contrib/modules\n",
      "--     Version control (extra):     4.10.0-22-g0377a6af\n",
      "-- \n",
      "--   Platform:\n",
      "--     Timestamp:                   2024-09-15T11:34:40Z\n",
      "--     Host:                        Linux 5.15.154+ x86_64\n",
      "--     CMake:                       3.22.1\n",
      "--     CMake generator:             Unix Makefiles\n",
      "--     CMake build tool:            /usr/bin/gmake\n",
      "--     Configuration:               Release\n",
      "--     Algorithm Hint:              ALGO_HINT_ACCURATE\n",
      "-- \n",
      "--   CPU/HW features:\n",
      "--     Baseline:                    SSE SSE2 SSE3\n",
      "--       requested:                 SSE3\n",
      "--     Dispatched code generation:  SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX\n",
      "--       SSE4_1 (16 files):         + SSSE3 SSE4_1\n",
      "--       SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2\n",
      "--       AVX (8 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX\n",
      "--       FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 AVX FP16\n",
      "--       AVX2 (36 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 AVX FP16 AVX2 FMA3\n",
      "--       AVX512_SKX (5 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 AVX FP16 AVX2 FMA3 AVX_512F AVX512_COMMON AVX512_SKX\n",
      "-- \n",
      "--   C/C++:\n",
      "--     Built as dynamic libs?:      NO\n",
      "--     C++ standard:                11\n",
      "--     C++ Compiler:                /usr/bin/c++  (ver 11.4.0)\n",
      "--     C++ flags (Release):         -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG\n",
      "--     C++ flags (Debug):           -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG\n",
      "--     C Compiler:                  /usr/bin/cc\n",
      "--     C flags (Release):           -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG\n",
      "--     C flags (Debug):             -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG\n",
      "--     Linker flags (Release):      -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a   -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  \n",
      "--     Linker flags (Debug):        -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a   -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  \n",
      "--     ccache:                      NO\n",
      "--     Precompiled headers:         NO\n",
      "--     Extra dependencies:          /usr/lib/x86_64-linux-gnu/libjpeg.so /usr/lib/x86_64-linux-gnu/libpng.so openjp2 /opt/conda/lib/libfreetype.so /opt/conda/lib/libharfbuzz.so /usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so /usr/lib/x86_64-linux-gnu/libcrypto.so /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libpthread.a /usr/lib/x86_64-linux-gnu/libsz.so /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.a /usr/lib/x86_64-linux-gnu/libm.so Iconv::Iconv m pthread cudart_static dl rt CUDA_nppc_LIBRARY-NOTFOUND CUDA_nppial_LIBRARY-NOTFOUND CUDA_nppicc_LIBRARY-NOTFOUND CUDA_nppidei_LIBRARY-NOTFOUND CUDA_nppif_LIBRARY-NOTFOUND CUDA_nppig_LIBRARY-NOTFOUND CUDA_nppim_LIBRARY-NOTFOUND CUDA_nppist_LIBRARY-NOTFOUND CUDA_nppisu_LIBRARY-NOTFOUND CUDA_nppitc_LIBRARY-NOTFOUND CUDA_npps_LIBRARY-NOTFOUND cublas cudnn CUDA_cufft_LIBRARY-NOTFOUND -L/opt/conda/targets/x86_64-linux/lib -L/usr/lib/x86_64-linux-gnu\n",
      "--     3rdparty dependencies:       libprotobuf ade ittnotify libwebp libtiff ippiw ippicv\n",
      "-- \n",
      "--   OpenCV modules:\n",
      "--     To be built:                 aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann freetype fuzzy gapi hdf hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot quality rapid reg rgbd saliency shape signal stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto\n",
      "--     Disabled:                    world\n",
      "--     Disabled by dependency:      -\n",
      "--     Unavailable:                 alphamat cannops cvv java julia matlab ovis python2 python3 sfm ts viz\n",
      "--     Applications:                apps\n",
      "--     Documentation:               NO\n",
      "--     Non-free algorithms:         NO\n",
      "-- \n",
      "--   GUI:                           GTK2\n",
      "--     GTK+:                        YES (ver 2.24.33)\n",
      "--       GtkGlExt:                  NO\n",
      "--     VTK support:                 NO\n",
      "-- \n",
      "--   Media I/O: \n",
      "--     ZLib:                        /usr/lib/x86_64-linux-gnu/libz.so (ver 1.2.11)\n",
      "--     JPEG:                        /usr/lib/x86_64-linux-gnu/libjpeg.so (ver 80)\n",
      "--     WEBP:                        build (ver encoder: 0x020f)\n",
      "--     PNG:                         /usr/lib/x86_64-linux-gnu/libpng.so (ver 1.6.37)\n",
      "--     TIFF:                        build (ver 42 - 4.6.0)\n",
      "--     JPEG 2000:                   OpenJPEG (ver 2.5.2)\n",
      "--     HDR:                         YES\n",
      "--     SUNRASTER:                   YES\n",
      "--     PXM:                         YES\n",
      "--     PFM:                         YES\n",
      "-- \n",
      "--   Video I/O:\n",
      "--     FFMPEG:                      NO\n",
      "--       avcodec:                   NO\n",
      "--       avformat:                  NO\n",
      "--       avutil:                    NO\n",
      "--       swscale:                   NO\n",
      "--       avresample:                NO\n",
      "--     GStreamer:                   NO\n",
      "--     v4l/v4l2:                    YES (linux/videodev2.h)\n",
      "-- \n",
      "--   Parallel framework:            pthreads\n",
      "-- \n",
      "--   Trace:                         YES (with Intel ITT)\n",
      "-- \n",
      "--   Other third-party libraries:\n",
      "--     Intel IPP:                   2021.12.0 [2021.12.0]\n",
      "--            at:                   /kaggle/working/build/3rdparty/ippicv/ippicv_lnx/icv\n",
      "--     Intel IPP IW:                sources (2021.12.0)\n",
      "--               at:                /kaggle/working/build/3rdparty/ippicv/ippicv_lnx/iw\n",
      "--     VA:                          NO\n",
      "--     Lapack:                      NO\n",
      "--     Eigen:                       NO\n",
      "--     Custom HAL:                  NO\n",
      "--     Protobuf:                    build (3.19.1)\n",
      "--     Flatbuffers:                 builtin/3rdparty (23.5.9)\n",
      "-- \n",
      "--   NVIDIA CUDA:                   YES (ver 12.3, CUFFT CUBLAS)\n",
      "--     NVIDIA GPU arch:\n",
      "--     NVIDIA PTX archs:\n",
      "-- \n",
      "--   cuDNN:                         YES (ver 9.0.0)\n",
      "-- \n",
      "--   OpenCL:                        YES (no extra features)\n",
      "--     Include path:                /kaggle/working/opencv/3rdparty/include/opencl/1.2\n",
      "--     Link libraries:              Dynamic load\n",
      "-- \n",
      "--   Python (for build):            /opt/conda/bin/python3\n",
      "-- \n",
      "--   Java:                          \n",
      "--     ant:                         NO\n",
      "--     Java:                        NO\n",
      "--     JNI:                         NO\n",
      "--     Java wrappers:               NO\n",
      "--     Java tests:                  NO\n",
      "-- \n",
      "--   Install to:                    /usr/local\n",
      "-- -----------------------------------------------------------------\n",
      "-- \n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "-- Configuring incomplete, errors occurred!\n",
      "See also \"/kaggle/working/build/CMakeFiles/CMakeOutput.log\".\n",
      "See also \"/kaggle/working/build/CMakeFiles/CMakeError.log\".\n",
      "make: *** No rule to make target 'install'.  Stop.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /kaggle/working/build\n",
    "\n",
    "!cmake -DOPENCV_EXTRA_MODULES_PATH=/kaggle/working/opencv_contrib/modules  \\\n",
    "       -DBUILD_SHARED_LIBS=OFF \\\n",
    "       -DBUILD_TESTS=OFF \\\n",
    "       -DBUILD_PERF_TESTS=OFF \\\n",
    "       -DBUILD_EXAMPLES=OFF \\\n",
    "       -DWITH_OPENEXR=OFF \\\n",
    "       -DWITH_CUDA=ON \\\n",
    "       -DWITH_CUBLAS=ON \\\n",
    "       -DWITH_CUDNN=ON \\\n",
    "       -DOPENCV_DNN_CUDA=ON \\\n",
    "       /kaggle/working/opencv\n",
    "\n",
    "!make -j8 install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:30:08.164416Z",
     "iopub.status.busy": "2024-09-15T11:30:08.163895Z",
     "iopub.status.idle": "2024-09-15T11:30:20.630686Z",
     "shell.execute_reply": "2024-09-15T11:30:20.629487Z",
     "shell.execute_reply.started": "2024-09-15T11:30:08.164374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:35:22.784196Z",
     "iopub.status.busy": "2024-09-15T11:35:22.783424Z",
     "iopub.status.idle": "2024-09-15T11:35:25.628058Z",
     "shell.execute_reply": "2024-09-15T11:35:25.627123Z",
     "shell.execute_reply.started": "2024-09-15T11:35:22.784157Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader using GPU: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "print(\"Reader using GPU:\", reader.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:35:06.386933Z",
     "iopub.status.busy": "2024-09-15T11:35:06.385782Z",
     "iopub.status.idle": "2024-09-15T11:35:06.391644Z",
     "shell.execute_reply": "2024-09-15T11:35:06.390706Z",
     "shell.execute_reply.started": "2024-09-15T11:35:06.386891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Enabled Device Count: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(\"CUDA Enabled Device Count:\", cv2.cuda.getCudaEnabledDeviceCount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:35:31.010418Z",
     "iopub.status.busy": "2024-09-15T11:35:31.010036Z",
     "iopub.status.idle": "2024-09-15T11:35:31.015696Z",
     "shell.execute_reply": "2024-09-15T11:35:31.014740Z",
     "shell.execute_reply.started": "2024-09-15T11:35:31.010381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from rapidfuzz import process\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from utils import download_image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:35:31.230279Z",
     "iopub.status.busy": "2024-09-15T11:35:31.229974Z",
     "iopub.status.idle": "2024-09-15T11:35:31.244759Z",
     "shell.execute_reply": "2024-09-15T11:35:31.243819Z",
     "shell.execute_reply.started": "2024-09-15T11:35:31.230240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the dictionary with full forms and abbreviations\n",
    "unit_fullform_to_abbreviation = {\n",
    "    'centimetre': ['cm', 'centimeter', 'centimetres', 'centimeters'],\n",
    "    'millimetre': ['mm', 'millimeter', 'millimetres', 'millimeters'],\n",
    "    'metre': ['m', 'meter', 'meters', 'metres'],\n",
    "    'inch': ['in', 'inches', '\"'],\n",
    "    'foot': ['ft', 'feet', \"'\"],\n",
    "    'yard': ['yd', 'yards'],\n",
    "    'gram': ['g', 'gm', 'gms', 'grams'],\n",
    "    'kilogram': ['kg', 'kgs', 'kilograms'],\n",
    "    'milligram': ['mg', 'mgs', 'milligrams'],\n",
    "    'microgram': ['mcg', 'μg', 'micrograms'],\n",
    "    'ounce': ['oz', 'ounces'],\n",
    "    'pound': ['lb', 'lbs', 'pounds'],\n",
    "    'ton': ['t', 'tonne', 'tonnes', 'tons'],\n",
    "    'volt': ['v', 'volts'],\n",
    "    'kilovolt': ['kv', 'kilovolts'],\n",
    "    'millivolt': ['mv', 'millivolts'],\n",
    "    'watt': ['w', 'watts'],\n",
    "    'kilowatt': ['kw', 'kilowatts'],\n",
    "    'litre': ['l', 'liters', 'litre', 'litres'],\n",
    "    'millilitre': ['ml', 'milliliters', 'millilitres', 'mls'],\n",
    "    'centilitre': ['cl', 'centiliters', 'centilitres'],\n",
    "    'decilitre': ['dl', 'deciliters', 'decilitres'],\n",
    "    'cubic foot': ['cu ft', 'ft³'],\n",
    "    'cubic inch': ['cu in', 'in³'],\n",
    "    'fluid ounce': ['fl oz', 'fluid ounces'],\n",
    "    'gallon': ['gal', 'gallons'],\n",
    "    'imperial gallon': ['imp gal', 'imperial gallons'],\n",
    "    'pint': ['pt', 'pints'],\n",
    "    'quart': ['qt', 'quarts'],\n",
    "    'microlitre': ['ul', 'μl', 'microlitres', 'microliters'],\n",
    "    'cup': ['cup', 'cups']\n",
    "}\n",
    "\n",
    "# Unit conversion factors to smallest units (e.g., mm for length, mg for weight, mv for voltage)\n",
    "conversion_factors_to_smallest = {\n",
    "    'millimetre': 1, 'centimetre': 10, 'metre': 1000, 'inch': 25.4, 'foot': 304.8, 'yard': 914.4,\n",
    "    'milligram': 1, 'gram': 1000, 'kilogram': 1000000, 'microgram': 0.001, 'ounce': 28349.5, 'pound': 453592, 'ton': 1000000000,\n",
    "    'millivolt': 1, 'volt': 1000, 'kilovolt': 1000000,\n",
    "    'millilitre': 1, 'litre': 1000, 'centilitre': 10, 'decilitre': 100,\n",
    "    'fluid ounce': 29.5735, 'gallon': 3785.41, 'pint': 473.176, 'quart': 946.353,\n",
    "    'microlitre': 0.001, 'cubic inch': 16.3871, 'cubic foot': 28316.8,\n",
    "    'watt': 1, 'kilowatt': 1000\n",
    "}\n",
    "\n",
    "# Classify units into categories\n",
    "unit_categories = {\n",
    "    'length': {'millimetre', 'centimetre', 'metre', 'inch', 'foot', 'yard'},\n",
    "    'weight': {'milligram', 'gram', 'kilogram', 'microgram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'millivolt', 'volt', 'kilovolt'},\n",
    "    'volume': {'millilitre', 'litre', 'centilitre', 'decilitre', 'fluid ounce', 'gallon', 'pint', 'quart', 'microlitre', 'cubic inch', 'cubic foot'},\n",
    "    'wattage': {'watt', 'kilowatt'}\n",
    "}\n",
    "\n",
    "# Flatten the unit list for fuzzy matching\n",
    "all_units = [abbrev for unit_list in unit_fullform_to_abbreviation.values()\n",
    "             for abbrev in unit_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:52:30.372609Z",
     "iopub.status.busy": "2024-09-15T11:52:30.371680Z",
     "iopub.status.idle": "2024-09-15T11:52:30.378956Z",
     "shell.execute_reply": "2024-09-15T11:52:30.377865Z",
     "shell.execute_reply.started": "2024-09-15T11:52:30.372548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to extract numbers and their (possibly misspelled) units\n",
    "def extract_numbers_with_units(text):\n",
    "    # Regex to match numbers followed by potential unit strings\n",
    "    pattern = r'(\\d+(\\.\\d+)?)(\\s*)([a-zA-Z]+)'\n",
    "    # pattern = r'(\\d+((\\.)+\\d+)?)(\\s*)([a-zA-Z]+)'\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    results = []\n",
    "    # Iterate over all matches\n",
    "    for match in matches:\n",
    "        number = match[0]  # The number (either integer or decimal)\n",
    "        # The potential unit (word following the number)\n",
    "        unit_candidate = match[3]\n",
    "        # Fuzzy match the unit candidate to the closest valid unit\n",
    "        results_fuzzy = process.extractOne(\n",
    "            unit_candidate, all_units, score_cutoff=95)\n",
    "        if results_fuzzy:\n",
    "            matched_unit = results_fuzzy\n",
    "            # If a match is found with a reasonable score, append the result\n",
    "            results.append(f\"{number} {matched_unit[0]}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:35:31.647776Z",
     "iopub.status.busy": "2024-09-15T11:35:31.647469Z",
     "iopub.status.idle": "2024-09-15T11:35:31.653332Z",
     "shell.execute_reply": "2024-09-15T11:35:31.652409Z",
     "shell.execute_reply.started": "2024-09-15T11:35:31.647744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''PART 2'''\n",
    "# Separating the numbers and units\n",
    "def separate_numbers_and_units(output):\n",
    "    numbers_list = []\n",
    "    units_list = []\n",
    "    for item in output:\n",
    "        match = re.match(r'([0-9.]+)\\s*(\\w+)', item)\n",
    "        if match:\n",
    "            number, unit = match.groups()\n",
    "            numbers_list.append(number)\n",
    "            units_list.append(unit)\n",
    "\n",
    "    return numbers_list, units_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:35:31.977654Z",
     "iopub.status.busy": "2024-09-15T11:35:31.977340Z",
     "iopub.status.idle": "2024-09-15T11:35:31.985580Z",
     "shell.execute_reply": "2024-09-15T11:35:31.984613Z",
     "shell.execute_reply.started": "2024-09-15T11:35:31.977621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''PART 3'''\n",
    "\n",
    "# Create a set of all allowed full forms\n",
    "allowed_units = set(unit_fullform_to_abbreviation.keys())\n",
    "\n",
    "\n",
    "# Function to get full unit or blank space\n",
    "def get_full_unit(unit_input):\n",
    "    # Use regex to convert the input to lowercase and strip any extra spaces\n",
    "    unit_input = re.sub(r'\\s+', ' ', unit_input.lower().strip())\n",
    "\n",
    "    # Check if the input matches any abbreviation or full form\n",
    "    for full_unit, abbreviations in unit_fullform_to_abbreviation.items():\n",
    "        if unit_input == full_unit or unit_input in abbreviations:\n",
    "            return full_unit\n",
    "\n",
    "    # If no match, return blank\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def convert_to_full_unit(input_text):\n",
    "    final_result = []\n",
    "    result = []\n",
    "    numbers = []\n",
    "    units = []\n",
    "    # Getting the initial output\n",
    "    output = extract_numbers_with_units(input_text)\n",
    "    # print(\"Extracted values:\", output)\n",
    "\n",
    "    numbers, units = separate_numbers_and_units(output)\n",
    "\n",
    "    # print(\"Numbers:\", numbers)\n",
    "    # print(\"Units:\", units)\n",
    "\n",
    "    # Getting full forms of units\n",
    "    for unit in units:\n",
    "        unit_fullform = get_full_unit(unit)\n",
    "        result.append(unit_fullform)\n",
    "\n",
    "    # Combine numbers and full units in the desired format\n",
    "    final_result = [f\"{num} {unit}\" for num, unit in zip(numbers, result)]\n",
    "    return final_result, numbers, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:52:18.731831Z",
     "iopub.status.busy": "2024-09-15T11:52:18.730869Z",
     "iopub.status.idle": "2024-09-15T11:52:18.743823Z",
     "shell.execute_reply": "2024-09-15T11:52:18.742719Z",
     "shell.execute_reply.started": "2024-09-15T11:52:18.731783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def categorize_values(numbers, result):\n",
    "    categorized_values = {\n",
    "        'length': [],\n",
    "        'weight': [],\n",
    "        'voltage': [],\n",
    "        'volume': [],\n",
    "        'wattage': []\n",
    "    }\n",
    "\n",
    "    # full_units, _ = convert_to_full_unit(', '.join(input_list))\n",
    "\n",
    "    # numbers, _ = separate_numbers_and_units(input_list)\n",
    "\n",
    "    for num, unit in zip(numbers, result):\n",
    "        for category, unit_set in unit_categories.items():\n",
    "            if unit in unit_set:\n",
    "                converted_value = float(\n",
    "                    num) * conversion_factors_to_smallest[unit]\n",
    "                categorized_values[category].append(\n",
    "                    (converted_value, f\"{float(num)} {unit}\"))\n",
    "\n",
    "    return categorized_values\n",
    "\n",
    "def get_entity_value(entity_value, categorized_values):\n",
    "    # Return based on entity type\n",
    "    if entity_value == 'item_weight' or entity_value == 'maximum_weight_recommendation':\n",
    "        if categorized_values['weight']:\n",
    "            # Largest weight\n",
    "            return max(categorized_values['weight'], key=lambda x: x[0])[1]\n",
    "    elif entity_value == 'voltage':\n",
    "        if categorized_values['voltage']:\n",
    "            # Largest voltage\n",
    "            return max(categorized_values['voltage'], key=lambda x: x[0])[1]\n",
    "    elif entity_value == 'item_volume':\n",
    "        if categorized_values['volume']:\n",
    "            # Largest volume\n",
    "            return max(categorized_values['volume'], key=lambda x: x[0])[1]\n",
    "    elif entity_value == 'wattage':\n",
    "        if categorized_values['wattage']:\n",
    "            # Largest wattage\n",
    "            return max(categorized_values['wattage'], key=lambda x: x[0])[1]\n",
    "    elif entity_value in ['width', 'depth', 'height']:\n",
    "        if categorized_values['length']:\n",
    "            if entity_value == 'width':\n",
    "                # Smallest length for width\n",
    "                return min(categorized_values['length'], key=lambda x: x[0])[1]\n",
    "            else:\n",
    "                # Largest length for depth/height\n",
    "                return max(categorized_values['length'], key=lambda x: x[0])[1]\n",
    "\n",
    "    return None  # If no valid match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:52:22.849468Z",
     "iopub.status.busy": "2024-09-15T11:52:22.848580Z",
     "iopub.status.idle": "2024-09-15T11:52:22.862555Z",
     "shell.execute_reply": "2024-09-15T11:52:22.861637Z",
     "shell.execute_reply.started": "2024-09-15T11:52:22.849420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def easyocr_model(image):\n",
    "    reader = easyocr.Reader(['en'], gpu = True)\n",
    "    result = reader.readtext(image)\n",
    "    text = ' '.join([item[1] for item in result])\n",
    "    return text\n",
    "\n",
    "\n",
    "# def grayscale(image):\n",
    "#     return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def grayscale(image):\n",
    "    # Use OpenCV CUDA for faster grayscale conversion if available\n",
    "    if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "        image_gpu = cv2.cuda_GpuMat()\n",
    "        image_gpu.upload(image)\n",
    "        gray_gpu = cv2.cuda.cvtColor(image_gpu, cv2.COLOR_BGR2GRAY)\n",
    "        gray_image = gray_gpu.download()\n",
    "    else:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_image\n",
    "\n",
    "\n",
    "# Function to download image and load it in memory\n",
    "def load_image_from_url(image_url):\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            return image\n",
    "        else:\n",
    "            print(f\"Failed to download image from {image_url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def inversion_check(img):\n",
    "    gray_image = grayscale(img)\n",
    "\n",
    "    # Determine if background is light or dark by calculating the mean pixel intensity\n",
    "    mean_intensity = np.mean(gray_image)\n",
    "    print(mean_intensity)\n",
    "\n",
    "    # Set a threshold to distinguish between dark and light backgrounds\n",
    "    # If the mean intensity is lower than this value, we consider the background dark\n",
    "    threshold_intensity = 127  # Midpoint in range [0, 255]\n",
    "\n",
    "    if mean_intensity < threshold_intensity:\n",
    "        # If background is dark (mean intensity is low), invert the image\n",
    "        gray_image = cv2.bitwise_not(gray_image)\n",
    "    return gray_image\n",
    "\n",
    "\n",
    "# def sharpen_image(gray_image):\n",
    "#     # Sharpening kernel\n",
    "#     kernel = np.array([[0, -1, 0],\n",
    "#                        [-1, 5, -1],\n",
    "#                        [0, -1, 0]])\n",
    "\n",
    "#     # Apply the sharpening kernel to the image\n",
    "#     sharpened = cv2.filter2D(gray_image, -1, kernel)\n",
    "#     return sharpened\n",
    "\n",
    "def sharpen_image(gray_image):\n",
    "    # Use OpenCV CUDA for sharpening if available\n",
    "    if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "        gray_gpu = cv2.cuda_GpuMat()\n",
    "        gray_gpu.upload(gray_image)\n",
    "\n",
    "        # Sharpening kernel\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5, -1],\n",
    "                           [0, -1, 0]])\n",
    "\n",
    "        kernel_gpu = cv2.cuda_GpuMat()\n",
    "        kernel_gpu.upload(kernel)\n",
    "\n",
    "        # Apply the sharpening kernel to the image on the GPU\n",
    "        sharpened_gpu = cv2.cuda.filter2D(gray_gpu, -1, kernel)\n",
    "        sharpened = sharpened_gpu.download()\n",
    "    else:\n",
    "        # Sharpen on the CPU if no CUDA support\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5, -1],\n",
    "                           [0, -1, 0]])\n",
    "        sharpened = cv2.filter2D(gray_image, -1, kernel)\n",
    "    return sharpened\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(output_csv):\n",
    "    if not os.path.isfile(output_csv):\n",
    "            output_df.to_csv(output_csv, index=False, columns=['index_id', 'entity_name', 'extracted_text'])\n",
    "        \n",
    "    with open(output_csv, newline='') as infile, open(output_csv, mode='w', newline='') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        # Write the header for the output CSV\n",
    "        writer.writerow([\"index_id\", \"extracted_text\"])\n",
    "\n",
    "        index_id = 0\n",
    "        for row in reader:\n",
    "            image_url = row['image_link']\n",
    "            image = download_image(image_url)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Detect text\n",
    "            detected_text = detect_text_east(image, east_model_path)\n",
    "\n",
    "            # Write the result to the output CSV\n",
    "            writer.writerow([index_id, detected_text])\n",
    "            index_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:52:40.231398Z",
     "iopub.status.busy": "2024-09-15T11:52:40.230974Z",
     "iopub.status.idle": "2024-09-15T11:52:40.398410Z",
     "shell.execute_reply": "2024-09-15T11:52:40.397604Z",
     "shell.execute_reply.started": "2024-09-15T11:52:40.231358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "# Update with the path to your input CSV\n",
    "input_csv = '/kaggle/input/amazon-ml-2024/test.csv'\n",
    "output_csv = '/kaggle/working/output.csv'  # Path to save the output CSV\n",
    "\n",
    "data = pd.read_csv(input_csv)\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "batch_size = 5  # Set the interval to save results (e.g., every 5 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T11:57:27.869512Z",
     "iopub.status.busy": "2024-09-15T11:57:27.868595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image: https://m.media-amazon.com/images/I/110EibNyclL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54F00AE8F0>\n",
      "253.842188\n",
      "['5144 metre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/11TU2clswzL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x65 at 0x7E53BC99EB60>\n",
      "250.10558461538463\n",
      "['42 centimetre', '200 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/11TU2clswzL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x65 at 0x7E54F00AF0A0>\n",
      "250.10558461538463\n",
      "['42 centimetre', '200 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/11TU2clswzL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x65 at 0x7E53BC1D6B60>\n",
      "250.10558461538463\n",
      "['42 centimetre', '200 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x65 at 0x7E53C7CFBEE0>\n",
      "250.10224615384615\n",
      "['10.50 centimetre', '90 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x65 at 0x7E53BCAAE0B0>\n",
      "250.10224615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.50 centimetre', '90 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x65 at 0x7E53C7CF8370>\n",
      "250.10224615384615\n",
      "['10.50 centimetre', '90 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/11lshEUmCrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC1D6A70>\n",
      "250.4616\n",
      "['7 pound', '4 metre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21+i52HRW4L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C7CFABF0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21-LmSmehZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54F00AECE0>\n",
      "251.31842041015625\n",
      "['40 centimetre', '30 centimetre', '15 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/213oP6n7jtL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x7E53BC99C4C0>\n",
      "204.959875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/213wY3gUsmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x171 at 0x7E53BCAAD030>\n",
      "236.9709707602339\n",
      "['30.6 centimetre', '6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/214CLs1oznL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54F00AECE0>\n",
      "247.935904\n",
      "['43 inch', '10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/214CLs1oznL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC1D55D0>\n",
      "247.935904\n",
      "['43 inch', '10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/214CLs1oznL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAE860>\n",
      "247.935904\n",
      "['43 inch', '10 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/216rjgJHAeL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=175x175 at 0x7E53BCAAE230>\n",
      "215.52741224489796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/2174yonQBtL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=89x500 at 0x7E53D4B2FD90>\n",
      "219.49224719101124\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/218BCzgKxuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x151 at 0x7E53BCAAD0F0>\n",
      "245.09638410596025\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/218BCzgKxuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x151 at 0x7E53BC99C610>\n",
      "245.09638410596025\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/218BCzgKxuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x151 at 0x7E53BCAAE3B0>\n",
      "245.09638410596025\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21BMc5GC4iL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7E53C7CFAD70>\n",
      "247.1618198198198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21CxlWbim3L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x280 at 0x7E54F00AE8F0>\n",
      "246.67159285714285\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21DZ7BAZ6-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=190x246 at 0x7E53C7CFBA90>\n",
      "213.36016260162603\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21GLFXwC1mS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAE4A0>\n",
      "251.177872\n",
      "['032 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21GLFXwC1mS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC9E2CB0>\n",
      "251.177872\n",
      "['032 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21H+7R85YZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC99D7B0>\n",
      "244.801472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.8 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21H+7R85YZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC9E3490>\n",
      "244.801472\n",
      "['3.8 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21IGmiJi-PL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=113x150 at 0x7E54F00AE8F0>\n",
      "180.31097345132744\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21Is45vdL0L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAE6E0>\n",
      "250.685864\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21Raw7jSIML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x224 at 0x7E53BC99CAF0>\n",
      "226.81420535714287\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21Vc5ixqKpS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC99D2D0>\n",
      "247.904644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['701 centimetre', '19 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21W7FvftSCL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x434 at 0x7E54F00AECE0>\n",
      "246.1711198156682\n",
      "['90 millimetre', '200 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21aD6ktvwxS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC99CAF0>\n",
      "241.61114666666666\n",
      "['5.8 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21aD6ktvwxS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC9E36D0>\n",
      "241.61114666666666\n",
      "['5.8 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21aD6ktvwxS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E54F00AECE0>\n",
      "241.61114666666666\n",
      "['5.8 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21bfrFeArAL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=160x160 at 0x7E53BC9E3640>\n",
      "189.1384375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21bwWoCpGJL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x129 at 0x7E53BC99C130>\n",
      "249.1248062015504\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21cLufe8Y5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x26 at 0x7E53D4B2FD90>\n",
      "136.02638461538461\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21cLufe8Y5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x26 at 0x7E53BC9E3580>\n",
      "136.02638461538461\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21d6Dtc94mL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC1D6A70>\n",
      "250.719232\n",
      "['120 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21d6Dtc94mL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC1D55D0>\n",
      "250.719232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['120 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21fIe0wHxDL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x251 at 0x7E53BCAAC1C0>\n",
      "245.576\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21jOOqo0oZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54F00AECE0>\n",
      "246.890068\n",
      "['48 inch', '122 centimetre', '96 inch', '244 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21jOOqo0oZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC9E3340>\n",
      "246.890068\n",
      "['48 inch', '122 centimetre', '96 inch', '244 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21lqVGTzV1L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC99EB60>\n",
      "246.191944\n",
      "['1 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21m65YQrQdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC9E34F0>\n",
      "226.48433066666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21m65YQrQdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BCAAE6E0>\n",
      "226.48433066666666\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21m65YQrQdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC9E3D90>\n",
      "226.48433066666666\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21nEy7KBQlL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAE0B0>\n",
      "244.640696\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21nEy7KBQlL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC9E1930>\n",
      "244.640696\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21nEy7KBQlL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAE440>\n",
      "244.640696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21pFwZ8ghkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x81 at 0x7E53BD338370>\n",
      "232.14553086419753\n",
      "['200 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21pFwZ8ghkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x81 at 0x7E53BCAAE320>\n",
      "232.14553086419753\n",
      "['200 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21qcJWXFNkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C43E50>\n",
      "247.798592\n",
      "['19 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21qcJWXFNkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAACF40>\n",
      "247.798592\n",
      "['19 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21qgWY60ABL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x232 at 0x7E53BC99C610>\n",
      "246.17813793103448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12.7 centimetre', '187.96 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21qleENrBBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=120x109 at 0x7E54F00AF0A0>\n",
      "203.37224770642203\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21s+qly8nXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC99C4C0>\n",
      "250.637184\n",
      "['120 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21s+qly8nXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAE470>\n",
      "250.637184\n",
      "['120 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21tOerzlVML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54F00AF0A0>\n",
      "238.708868\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21tOerzlVML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5F250>\n",
      "238.708868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21twwj6e-VL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x73 at 0x7E53BCAAE230>\n",
      "198.06468493150686\n",
      "['6 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21vCDAVwSXS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=981x1000 at 0x7E53BC99C4C0>\n",
      "254.4445626911315\n",
      "['280 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21vCDAVwSXS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=981x1000 at 0x7E53C7C43FA0>\n",
      "254.4445626911315\n",
      "['280 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21vCDAVwSXS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=981x1000 at 0x7E53BE75D840>\n",
      "254.4445626911315\n",
      "['280 millimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21vv80MKQEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=121x500 at 0x7E53BC1D5D20>\n",
      "147.22052892561985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21xX4tzOqKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=380x240 at 0x7E54E5F5EB30>\n",
      "209.59798245614036\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21xnCHoPZHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x105 at 0x7E53BC1D6890>\n",
      "237.6364761904762\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21ykCJJsDpL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E54138BAD70>\n",
      "245.873536\n",
      "['10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21ykCJJsDpL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD528F40>\n",
      "245.873536\n",
      "['10 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/21ykCJJsDpL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BE75D840>\n",
      "245.873536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/21ztnqtFNVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD5280A0>\n",
      "232.33619733333333\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21ztnqtFNVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BE75D870>\n",
      "232.33619733333333\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/21ztnqtFNVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BE796230>\n",
      "232.33619733333333\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+1xiVjZBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD6D37C0>\n",
      "247.697832\n",
      "['230 millimetre', '160 millimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+1xiVjZBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5F250>\n",
      "247.697832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['230 millimetre', '160 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+21njYcOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1286x1286 at 0x7E53BE75D840>\n",
      "252.9948034703192\n",
      "['4.7 inch', '12 centimetre', '3.1 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+21njYcOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1286x1286 at 0x7E53BD528FD0>\n",
      "252.9948034703192\n",
      "['4.7 inch', '12 centimetre', '3.1 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+B4SvByXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x327 at 0x7E53BD528DF0>\n",
      "211.7483363914373\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+H+PVsNEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1600x1600 at 0x7E53D4AF6D10>\n",
      "254.361682421875\n",
      "['50 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+KMtY+QXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x278 at 0x7E53BD528B20>\n",
      "196.43028057553957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+KPbkPVPL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5EB30>\n",
      "169.566636\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+NHijx4tL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BE75D840>\n",
      "149.18744\n",
      "['11.1 pound', '5.05 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+RAxx7XaL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=334x500 at 0x7E54E5F5FF10>\n",
      "177.53035928143711\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+X1Lh3+eL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528BB0>\n",
      "247.633772\n",
      "['98 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+X1Lh3+eL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC1D6BC0>\n",
      "247.633772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['98 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+X1Lh3+eL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5EB30>\n",
      "247.633772\n",
      "['98 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+kevQrOnL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x151 at 0x7E53BE795960>\n",
      "91.7024238410596\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+kevQrOnL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x151 at 0x7E53BD6D37C0>\n",
      "91.7024238410596\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+kevQrOnL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x151 at 0x7E53BC1D5840>\n",
      "91.7024238410596\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+nz2egbjL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C415FD60>\n",
      "248.48381328582764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60 centimetre', '26 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+qzYwhJ9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD6D3760>\n",
      "195.367696\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+sbhHNfYS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD528FA0>\n",
      "237.15656089782715\n",
      "['400 millimetre', '500 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+zGAugKrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x416 at 0x7E53BD3386D0>\n",
      "243.20351923076922\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31+zdbOuiTL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x266 at 0x7E53D49AA860>\n",
      "205.5100626566416\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-4a-yI8sS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53D49ABC70>\n",
      "246.62213111563761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14 centimetre', '1 inch', '12.5 centimetre', '4.92 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-4a-yI8sS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BCAAF010>\n",
      "246.62213111563761\n",
      "['14 centimetre', '1 inch', '12.5 centimetre', '4.92 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-4uQ1S2XL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x247 at 0x7E53BCAAC910>\n",
      "218.33021862348178\n",
      "['9.6 volt', '56 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-7OAd1COL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD528F10>\n",
      "246.70601844787598\n",
      "['80 centimetre', '23.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-8fLBjX8L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BD3386D0>\n",
      "251.57170565085022\n",
      "['9 inch', '38 centimetre', '4.33 inch', '11 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-A90GRAHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BE75C7C0>\n",
      "215.78296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6 inch', '2 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-Jdk3SMUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=145x500 at 0x7E53C415D900>\n",
      "205.1424275862069\n",
      "['59 millilitre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-OBkMKDLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x240 at 0x7E53BF73CF70>\n",
      "242.97611666666666\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-QiMl+gwL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x469 at 0x7E53BD3380A0>\n",
      "241.30803411513858\n",
      "['90 centimetre', '86 centimetre', '62 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-Tp1rWTJL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD5141C0>\n",
      "247.00098609924316\n",
      "['40 centimetre', '35 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-Ubz8YvUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53C415D900>\n",
      "241.62719307270234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16 centimetre', '20 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-Ubz8YvUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BE7961A0>\n",
      "241.62719307270234\n",
      "['16 centimetre', '20 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-UedLQDqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53BD528040>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-W0zT17nL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=180x180 at 0x7E54E5F5FA30>\n",
      "142.4120061728395\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31-bBqUQPuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BC99C130>\n",
      "241.6834888458252\n",
      "['30 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310-VAupIJL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4B2F700>\n",
      "226.1243600845337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['80 centimetre', '25 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31014HApIqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=157x500 at 0x7E53D49BDAB0>\n",
      "151.6084203821656\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3101lgy28BL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BCAAC1F0>\n",
      "17.068872\n",
      "['650 watt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3101lgy28BL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD515450>\n",
      "17.068872\n",
      "['650 watt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3105qskWRcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=331x152 at 0x7E53BE75C7C0>\n",
      "92.84033630147877\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/3105qskWRcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=331x152 at 0x7E53BD5142B0>\n",
      "92.84033630147877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3106Kd8KjnL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5FF10>\n",
      "120.950208\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3106iDqsfQL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=143x500 at 0x7E53BC99D7E0>\n",
      "224.41323076923078\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3107VVwSyXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BC1D4940>\n",
      "226.70168193444917\n",
      "['3.9 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3107VVwSyXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BCAAE3E0>\n",
      "226.70168193444917\n",
      "['3.9 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310BVU1bXvL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x288 at 0x7E53BD3386D0>\n",
      "144.87258101851853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/310GYVrrJPS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=700x1010 at 0x7E53BD6D3700>\n",
      "243.84702687411598\n",
      "['7 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310ICDHEK-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x63 at 0x7E53BD3380A0>\n",
      "198.90650793650795\n",
      "['1 metre', '250 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310PNQ4FmqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x484 at 0x7E53D49A92D0>\n",
      "225.8479090909091\n",
      "['660 pound']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310Qevq+VSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=333x500 at 0x7E53C666DC30>\n",
      "235.65192792792791\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310Th3tbqRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=468x492 at 0x7E53D4B2F970>\n",
      "174.32316204572302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 volt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310Th3tbqRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=468x492 at 0x7E53BCAAD090>\n",
      "174.32316204572302\n",
      "['12 volt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310Tz9gnk2L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=427x500 at 0x7E53BC99FF70>\n",
      "237.82128337236534\n",
      "['29 centimetre', '51 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310VuJknGFS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BC1D4340>\n",
      "223.91885948181152\n",
      "['180 centimetre', '90 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310X-ftA6SL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4B2F970>\n",
      "163.781584\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310YvVAYofL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD5280D0>\n",
      "243.1037883758545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['40 centimetre', '31 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310aYU-JigL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1010x1010 at 0x7E53BE739360>\n",
      "250.50768356043525\n",
      "['25.6 inch', '65 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310aYU-JigL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1010x1010 at 0x7E53C666C940>\n",
      "250.50768356043525\n",
      "['25.6 inch', '65 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310aYU-JigL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1010x1010 at 0x7E53C77D5000>\n",
      "250.50768356043525\n",
      "['25.6 inch', '65 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310dh1DQxRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4A86D40>\n",
      "197.491676\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310hyjPrgML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BCAAE3E0>\n",
      "249.9907990397805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.9 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310hyjPrgML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BD513A90>\n",
      "249.9907990397805\n",
      "['2.9 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310kcUKMHOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53C77D5240>\n",
      "247.44952250546658\n",
      "['5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310mwtoWn3L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4A86D40>\n",
      "239.122648\n",
      "['29.95 centimetre', '85 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310oxdFmgLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BC99D9F0>\n",
      "239.526476\n",
      "['100 millimetre', '3.93 inch', '11.5 millimetre', '045 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310oxdFmgLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD6D3790>\n",
      "239.526476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100 millimetre', '3.93 inch', '11.5 millimetre', '045 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310p+AOeZ6L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BE795960>\n",
      "253.19457244873047\n",
      "['3 centimetre', '14 centimetre', '3.4 centimetre', '4 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310qlaeUSAL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD656E60>\n",
      "213.735284\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/310qlaeUSAL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528FA0>\n",
      "213.735284\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/310rX4WoAFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1020 at 0x7E53BCAAE3E0>\n",
      "245.30031430219145\n",
      "['90 centimetre', '35.4 inch', '3.9 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/310rX4WoAFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1020 at 0x7E53BE795960>\n",
      "245.30031430219145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['90 centimetre', '35.4 inch', '3.9 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310rX4WoAFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1020 at 0x7E53BD5154E0>\n",
      "245.30031430219145\n",
      "['90 centimetre', '35.4 inch', '3.9 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/310uxz1C1+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=161x500 at 0x7E53D49A91E0>\n",
      "213.35178881987576\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311+pYVZ1zL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E53BC1D4910>\n",
      "230.80379733333334\n",
      "['50 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311+pYVZ1zL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E53BD4EE410>\n",
      "230.80379733333334\n",
      "['50 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/3111QvQTfJL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=250x250 at 0x7E53D4B2FC70>\n",
      "217.749232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3113NMTt2CL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x251 at 0x7E53BD513A90>\n",
      "227.66436653386455\n",
      "['74.93 centimetre', '0 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3118BjQXgAL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BD4EE2C0>\n",
      "252.84411325288823\n",
      "['7.86 inch', '20 centimetre', '3.14 inch', '8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3118BjQXgAL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BCAAF010>\n",
      "252.84411325288823\n",
      "['7.86 inch', '20 centimetre', '3.14 inch', '8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31196HWGAjL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53D4B2FC70>\n",
      "239.805361\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31196HWGAjL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD6114E0>\n",
      "239.805361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311JBecauYL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BCAAF040>\n",
      "251.401537\n",
      "['50 millimetre', '1 litre', '8 millimetre', '35 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311KCsFxw9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x232 at 0x7E53BE739420>\n",
      "189.3339224137931\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311KCsFxw9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x232 at 0x7E53BD528BB0>\n",
      "189.3339224137931\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311KDyOGX-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x344 at 0x7E53C666EAD0>\n",
      "207.2282558139535\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/311M6XKGJhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BCAAC1F0>\n",
      "178.415334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311PssCBQIL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=180x500 at 0x7E53C77EA080>\n",
      "192.77003333333334\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311UTstDjGL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD656320>\n",
      "247.544736\n",
      "['82 centimetre', '157 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311ZqD+0WiL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x256 at 0x7E53BD4EC970>\n",
      "232.8730390625\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311d86W-TPL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=158x500 at 0x7E53BD3952A0>\n",
      "164.06922784810126\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/311dT7UohfS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC99C940>\n",
      "214.77416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311dT7UohfS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD6561A0>\n",
      "214.77416\n",
      "['2 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311e8av9T8L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77EBB80>\n",
      "240.310948\n",
      "['110 volt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311lBTY41pL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BC1D5BA0>\n",
      "247.702744\n",
      "['5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/311lBTY41pL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD4EC820>\n",
      "247.702744\n",
      "['5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/311nVBb35CL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=206x250 at 0x7E53C666F400>\n",
      "150.4188932038835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311qj00+z6L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x279 at 0x7E54132A2D10>\n",
      "149.23033691756274\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/311uqJG-v3L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77E8310>\n",
      "214.048116\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3121-R7e6gL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1263x1263 at 0x7E53BD5D6DA0>\n",
      "251.43765895651183\n",
      "['7.8 inch', '20.0 centimetre', '1.1 inch', '3.0 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3121-R7e6gL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1263x1263 at 0x7E53BD396050>\n",
      "251.43765895651183\n",
      "['7.8 inch', '20.0 centimetre', '1.1 inch', '3.0 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/312BjPAAlcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD4EE230>\n",
      "242.11013507843018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14 centimetre', '14 centimetre', '14 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/312DIk+dXDL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=158x250 at 0x7E53C77EB4F0>\n",
      "91.96655696202532\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/312aMY3cO9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C666F400>\n",
      "240.469274\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/312ux4Npq5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x320 at 0x7E53BC1D4070>\n",
      "162.89344375\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3130yji+ASL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1265x1265 at 0x7E53BD514070>\n",
      "252.94613819931573\n",
      "['5.9 inch', '15 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/3130yji+ASL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1265x1265 at 0x7E5412C4CC10>\n",
      "252.94613819931573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.9 inch', '15 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3131mkESkQL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BF73CF70>\n",
      "228.28234133333333\n",
      "['6.2 inch', '15 centimetre', '4 ton']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3136hKrB0xS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E54132A2350>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/313H+KOefpL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54132A2500>\n",
      "51.247728\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/313H+KOefpL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D49BDAB0>\n",
      "51.247728\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/313P9jCeUEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x145 at 0x7E54132A2350>\n",
      "87.48939310344828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/313PqxvaGFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BD513A90>\n",
      "243.90645318717247\n",
      "['7.19 centimetre', '5.08 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313PqxvaGFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BD5D6F50>\n",
      "243.90645318717247\n",
      "['7.19 centimetre', '5.08 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313Y-Pmq5OL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E54132A3160>\n",
      "252.66753298185688\n",
      "['2.7 inch', '7.0 centimetre', '11.0 inch', '28.0 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313Y-Pmq5OL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BC99F550>\n",
      "252.66753298185688\n",
      "['2.7 inch', '7.0 centimetre', '11.0 inch', '28.0 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/313ZWJXgMXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=438x500 at 0x7E53BC1D56F0>\n",
      "227.58670776255707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/313cKYWS+nL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x667 at 0x7E53BD513A90>\n",
      "252.39423838080958\n",
      "['40 centimetre', '61 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313cKYWS+nL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x667 at 0x7E53BD5D4FA0>\n",
      "252.39423838080958\n",
      "['40 centimetre', '61 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313gsCHpfeL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x312 at 0x7E53BD3952A0>\n",
      "187.34864102564103\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/313h5LWmlcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C415FD60>\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/313iZcTsPNL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x341 at 0x7E53D4B2FC70>\n",
      "246.51099706744867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4 centimetre', '33.3 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313iZcTsPNL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x341 at 0x7E53BC99F550>\n",
      "246.51099706744867\n",
      "['4 centimetre', '33.3 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/313rlTwmR9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4B2FC70>\n",
      "238.950272\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/313sSWfiIYL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C415FD60>\n",
      "238.745732\n",
      "['33 gram', '1 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3141MAkuatL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD4EE110>\n",
      "242.42410666666666\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31445Xcd2XL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1002x1002 at 0x7E53D4AF6F20>\n",
      "251.2609780439122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['37.5 centimetre', '14.76 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31445Xcd2XL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1002x1002 at 0x7E53BD6D39D0>\n",
      "251.2609780439122\n",
      "['37.5 centimetre', '14.76 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31445Xcd2XL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1002x1002 at 0x7E53D4A86D40>\n",
      "251.2609780439122\n",
      "['37.5 centimetre', '14.76 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3145h9GZigL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD513A90>\n",
      "227.043499\n",
      "['10 inch', '7.4 inch', '13.2 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3145h9GZigL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD339F30>\n",
      "227.043499\n",
      "['10 inch', '7.4 inch', '13.2 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/3147F5NHEdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4AF6D10>\n",
      "224.148216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3147F5NHEdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BE739420>\n",
      "224.148216\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31489jH+cnL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528FA0>\n",
      "189.794432\n",
      "['23.94 centimetre', '10.5 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314FxsDUTFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=167x230 at 0x7E53BD611510>\n",
      "115.29692788336371\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/314Gwp04mYL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=333x500 at 0x7E53BD4EE230>\n",
      "225.66466666666668\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/314J9z-v4HL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1000 at 0x7E53BD339E10>\n",
      "240.52202647058823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['213.5 millimetre', '85.7 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314NPHTZhwL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x100 at 0x7E53BD6D39D0>\n",
      "211.979\n",
      "['3 litre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314VKLwLwYL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=393x500 at 0x7E53C415FD60>\n",
      "156.59970992366414\n",
      "['75 centimetre', '25 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314gI8VlFOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD611480>\n",
      "152.027168\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/314oOH7ICvS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54138BAD70>\n",
      "208.27008819580078\n",
      "['30 centimetre', '3 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/314oOH7ICvS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4B2FF10>\n",
      "208.27008819580078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30 centimetre', '3 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314p2NKHdLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E5412C4C5E0>\n",
      "209.113092\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/314p2NKHdLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD6D3700>\n",
      "209.113092\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/314p2NKHdLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD6114E0>\n",
      "209.113092\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/314p4MOJlRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x199 at 0x7E53BD6D39D0>\n",
      "247.8293366834171\n",
      "['200 watt', '2.83 volt', '1 metre', '0 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/314vPdiXQFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4AF7190>\n",
      "248.374568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.7 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314vPdiXQFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BE739420>\n",
      "248.374568\n",
      "['2.7 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314wRJd39EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x246 at 0x7E53BD4EE470>\n",
      "201.83984552845527\n",
      "['43.18 centimetre', '90.17 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/314xpT+zaWL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x304 at 0x7E53C77E8790>\n",
      "186.59677631578947\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3158RU753EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E54E5F5F250>\n",
      "247.594521\n",
      "['3 foot']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/3158RU753EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD513F10>\n",
      "247.594521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 foot']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315C1CvRpTL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1025 at 0x7E53BD339E10>\n",
      "251.9727613582018\n",
      "['8.5 centimetre', '26 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315G27PSLxL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=286x500 at 0x7E53D4B2F880>\n",
      "219.71244755244754\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/315Mb5z2+RL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x111 at 0x7E53BD4EC790>\n",
      "231.50479279279278\n",
      "['37 pound', '2 inch', '38 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315PtJZRiFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=393x500 at 0x7E53D4B2F9D0>\n",
      "151.7406106870229\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/315PtJZRiFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=393x500 at 0x7E54E5F5F8E0>\n",
      "151.7406106870229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/315QF8BudHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C77EBE80>\n",
      "247.97792434692383\n",
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315SSiZLghL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BE739480>\n",
      "245.370192\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/315T7LAYrLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53BD4EFC70>\n",
      "239.76106388888888\n",
      "['70 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315T7LAYrLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53BD528EB0>\n",
      "239.76106388888888\n",
      "['70 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/315YvNM5jML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x257 at 0x7E53BD33A0E0>\n",
      "167.0310894941634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/315ZwdYq-nL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4A86D40>\n",
      "239.42084121704102\n",
      "['72 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315b6Zdm7BL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4AF7190>\n",
      "253.50094413757324\n",
      "['183 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315b6Zdm7BL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD528040>\n",
      "253.50094413757324\n",
      "['183 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315ldex3oEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4B2F9D0>\n",
      "249.48369121551514\n",
      "['60 centimetre', '60 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/315ldex3oEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E5519F88A00>\n",
      "249.48369121551514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60 centimetre', '60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315y3qqHQ1L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BE7961A0>\n",
      "250.07647895812988\n",
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315yDUfDBgL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1020 at 0x7E53BE75D870>\n",
      "249.6543646674356\n",
      "['7 centimetre', '21.5 centimetre', '8.46 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/315yDUfDBgL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1020x1020 at 0x7E53D4B2FE20>\n",
      "249.6543646674356\n",
      "['7 centimetre', '21.5 centimetre', '8.46 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3162jbDKLhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1002x1002 at 0x7E53BD528250>\n",
      "250.57626463639588\n",
      "['7.44 inch', '19 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31655QolL+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1081 at 0x7E53BE739420>\n",
      "250.9313367252544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15.1 centimetre', '7.6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31655QolL+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1081 at 0x7E53C77D4250>\n",
      "250.9313367252544\n",
      "['15.1 centimetre', '7.6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316JmynwTeL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD4EFFD0>\n",
      "226.23094\n",
      "['78 centimetre', '76 inch', '5 centimetre', '12 inch', '19 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316PuR+4P7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4B2FB50>\n",
      "248.45341205596924\n",
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316QBt0qRVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BD339AE0>\n",
      "249.94255191703175\n",
      "['2.32 inch', '5.9 centimetre', '4.6 inch', '11.7 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/316QBt0qRVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53D4B2F790>\n",
      "249.94255191703175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.32 inch', '5.9 centimetre', '4.6 inch', '11.7 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316QheTdnoL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x1000 at 0x7E53BE7961A0>\n",
      "233.89787125\n",
      "['97 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316X4m00znL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=166x500 at 0x7E53C77EBCA0>\n",
      "188.3651686746988\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/316cJ-vBGqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=144x500 at 0x7E53BD6D3760>\n",
      "208.88784722222223\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/316iYciADUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53BD6D39D0>\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/316pJ84mB-S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x1000 at 0x7E53C77EBA00>\n",
      "224.59303733333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316pJ84mB-S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x1000 at 0x7E53BD4EC7F0>\n",
      "224.59303733333334\n",
      "['16 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316pJ84mB-S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x1000 at 0x7E54132A3160>\n",
      "224.59303733333334\n",
      "['16 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316rD0Fy5eL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C77E82E0>\n",
      "243.07095527648926\n",
      "['76 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/316rD0Fy5eL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD5280A0>\n",
      "243.07095527648926\n",
      "['76 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/316rYL2JOBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5F160>\n",
      "206.14086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/316rYL2JOBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528E50>\n",
      "206.14086\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/316vEjFHFXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD4EC910>\n",
      "247.85004997253418\n",
      "['5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317+4WLmMhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1004x505 at 0x7E53BD528E50>\n",
      "243.34283854680288\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/317+4WLmMhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1004x505 at 0x7E53BE739360>\n",
      "243.34283854680288\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/3179bFOeHPL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BD528BB0>\n",
      "252.8345533162852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.55 inch', '6.5 centimetre', '2.3 inch', '6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3179bFOeHPL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BE75D870>\n",
      "252.8345533162852\n",
      "['2.55 inch', '6.5 centimetre', '2.3 inch', '6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3179z0kjMBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54132A2D10>\n",
      "230.647124\n",
      "['6 inch', '15.3 inch', '5 centimetre', '9.8 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317H4RZWLvL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BC99E0B0>\n",
      "242.375515\n",
      "['20 centimetre', '8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317H4RZWLvL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C77D6FE0>\n",
      "242.375515\n",
      "['20 centimetre', '8 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/317JgcKuEKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53C77EA140>\n",
      "250.7412249791006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.75 inch', '7 centimetre', '5.90 inch', '15 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317JgcKuEKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD6D3700>\n",
      "250.7412249791006\n",
      "['2.75 inch', '7 centimetre', '5.90 inch', '15 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317JgcKuEKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53C77E82E0>\n",
      "250.7412249791006\n",
      "['2.75 inch', '7 centimetre', '5.90 inch', '15 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317K7+0KVPL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=231x500 at 0x7E54132A3280>\n",
      "168.86806926406928\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/317UEfHNWFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD338370>\n",
      "239.45319574675773\n",
      "['1.5 inch', '4.0 centimetre', '6.4 inch', '16.5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/317UEfHNWFL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E5412C4CC10>\n",
      "239.45319574675773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.5 inch', '4.0 centimetre', '6.4 inch', '16.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/317V84vTmRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x237 at 0x7E53BD528F40>\n",
      "181.03237974683543\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/317e7XKMYmS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E53C666DF90>\n",
      "215.215744\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/317e7XKMYmS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E53C77D6D40>\n",
      "215.215744\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/317to6OSbEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD528DF0>\n",
      "251.61835927909195\n",
      "['1.9 inch', '5.0 centimetre', '8.2 inch', '21 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/317to6OSbEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E54E5F5EDA0>\n",
      "251.61835927909195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.9 inch', '5.0 centimetre', '8.2 inch', '21 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3182q3TzyTL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x338 at 0x7E53BC99F490>\n",
      "38.09396449704142\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3187NaQvGVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BE739360>\n",
      "241.421184\n",
      "['8 inch', '14 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/3187NaQvGVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53D4B2FDC0>\n",
      "241.421184\n",
      "['8 inch', '14 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/318JGZzqQLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=590x454 at 0x7E54132A3280>\n",
      "121.97728664227581\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/318NkZYUxbL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54E5F5E6B0>\n",
      "248.63931560516357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11 centimetre', '16.5 centimetre', '17 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/318R0lcGWuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528F10>\n",
      "224.44764\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/318TVw4iM1L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5F8E0>\n",
      "214.293816\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/318VrqotQiL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53C666D6C0>\n",
      "248.31491683813442\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/318VrqotQiL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53C77EBC10>\n",
      "248.31491683813442\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/318Vs-v1K+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x169 at 0x7E53BD6D3760>\n",
      "144.85623668639053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/318qeLWHofS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BE75D330>\n",
      "250.85541439056396\n",
      "['39 centimetre', '15.3 inch', '9 centimetre', '3.5 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/318qeLWHofS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54E5F5F160>\n",
      "250.85541439056396\n",
      "['39 centimetre', '15.3 inch', '9 centimetre', '3.5 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/318rqdGipZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528F10>\n",
      "219.200836\n",
      "['965 gram', '37 centimetre', '120 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/319+HHdREmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1286x1286 at 0x7E53BD6D39D0>\n",
      "249.20255279369403\n",
      "['4.4 inch', '11.2 centimetre', '2.55 inch', '5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/319+HHdREmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1286x1286 at 0x7E5412C4D1E0>\n",
      "249.20255279369403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.4 inch', '11.2 centimetre', '2.55 inch', '5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31933u5NyqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x253 at 0x7E53C77D7280>\n",
      "180.75771541501976\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/3196JaAmUXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD5D6EC0>\n",
      "252.63045024871826\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319PRYi9q9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54132A3760>\n",
      "20.509976\n",
      "['6 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/319PRYi9q9L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C40DF0>\n",
      "20.509976\n",
      "['6 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/319RcGrykvS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x303 at 0x7E53C77E82E0>\n",
      "251.15138613861387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4 metre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/319Utc-4JCL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=353x500 at 0x7E53BD515EA0>\n",
      "225.8360849858357\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319Utc-4JCL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=353x500 at 0x7E53C77D74C0>\n",
      "225.8360849858357\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319Utc-4JCL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=353x500 at 0x7E53D4A87520>\n",
      "225.8360849858357\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319YtUP6CdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BC99E0B0>\n",
      "253.07993597942504\n",
      "['9.5 centimetre', '1.2 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/319bXpAHHGL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD338100>\n",
      "241.522499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/319gwo27y5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4AF6D10>\n",
      "182.621152\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319mQCR3drL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C40670>\n",
      "205.047804\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319mw37uGgS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54F00AE8F0>\n",
      "208.498356\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/319rBAua1EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BE739360>\n",
      "234.7237007284658\n",
      "['0.9 inch', '2.2 centimetre', '1.8 inch', '4.5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/319rBAua1EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E54E5F5F8E0>\n",
      "234.7237007284658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.9 inch', '2.2 centimetre', '1.8 inch', '4.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31A-FrsRYJL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53BD5D6EF0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31A9glDJniL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x288 at 0x7E53BD6561A0>\n",
      "178.11210416666665\n",
      "['4 litre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AFs00-iML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=334x500 at 0x7E53BE75D330>\n",
      "165.69135928143712\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31ALW6ILdNS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53D4B2F9D0>\n",
      "246.642123\n",
      "['21 centimetre', '8.3 inch', '1.96 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31ALW6ILdNS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BC99CF70>\n",
      "246.642123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21 centimetre', '8.3 inch', '1.96 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31ALW6ILdNS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53D4A87520>\n",
      "246.642123\n",
      "['21 centimetre', '8.3 inch', '1.96 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AQgkAeoeS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C7C40DF0>\n",
      "243.10210037231445\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AQgkAeoeS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BC99CF70>\n",
      "243.10210037231445\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AW7fENOoL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD339E10>\n",
      "205.660668\n",
      "['39 centimetre', '15 inch', '0 gram']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AbZL7hGVS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD396B90>\n",
      "240.42556875733717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.95 inch', '20 centimetre', '7.86 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AbZL7hGVS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD6D3760>\n",
      "240.42556875733717\n",
      "['2.95 inch', '20 centimetre', '7.86 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AcYMtb32L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4B2FC10>\n",
      "176.312164\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AnSDFDuuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D5180>\n",
      "86.551436\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AnSDFDuuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E5412C4C100>\n",
      "86.551436\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AwVD2u6yS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BC9E3670>\n",
      "249.50866416300983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 inch', '11.5 centimetre', '4.53 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AwVD2u6yS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53C77EBCA0>\n",
      "249.50866416300983\n",
      "['1 inch', '11.5 centimetre', '4.53 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AwaGMCddL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53BD4EE320>\n",
      "248.12219049681588\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AwaGMCddL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53C7C40F40>\n",
      "248.12219049681588\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AwaGMCddL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1001x1001 at 0x7E53C666C700>\n",
      "248.12219049681588\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31AxondfXlL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77D44F0>\n",
      "205.032212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31B-428ClQL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x308 at 0x7E54F00AFC10>\n",
      "153.25047402597403\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31B2ZSdi-bS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BC9E27A0>\n",
      "250.53089675998118\n",
      "['40 centimetre', '15.72 inch', '15 centimetre', '5.89 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31B2ZSdi-bS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E54E5F5F160>\n",
      "250.53089675998118\n",
      "['40 centimetre', '15.72 inch', '15 centimetre', '5.89 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31B43FuEJSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x300 at 0x7E5412C4CC10>\n",
      "162.58026666666666\n",
      "['120 watt']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31B43FuEJSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x300 at 0x7E53BD6D3700>\n",
      "162.58026666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['120 watt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31B8KtbFc-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=154x500 at 0x7E53BC99C640>\n",
      "233.12787012987013\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BC3j4CS5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1266x1266 at 0x7E53BC99E0B0>\n",
      "253.8668655740487\n",
      "['0.7 inch', '2.0 centimetre', '4.9 inch', '12.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BC3j4CS5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1266x1266 at 0x7E54132A1900>\n",
      "253.8668655740487\n",
      "['0.7 inch', '2.0 centimetre', '4.9 inch', '12.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BE5BamUYS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D7040>\n",
      "193.146872\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BE5BamUYS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77D44F0>\n",
      "193.146872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BJdvLcS2L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD6D3700>\n",
      "115.597692\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BN3P0+FZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x1000 at 0x7E53C666EE90>\n",
      "231.32771066666666\n",
      "['25 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BN3P0+FZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x1000 at 0x7E53C7C41FC0>\n",
      "231.32771066666666\n",
      "['25 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BN3P0+FZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x1000 at 0x7E5412C4D3F0>\n",
      "231.32771066666666\n",
      "['25 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BVEDiDPxL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x307 at 0x7E53BD528F40>\n",
      "234.4213615635179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['75 centimetre', '120 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Bb9t5+zUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E54F00AED40>\n",
      "254.21490069444445\n",
      "['08.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Bb9t5+zUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53C77E9B70>\n",
      "254.21490069444445\n",
      "['08.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Bb9t5+zUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53C7C40370>\n",
      "254.21490069444445\n",
      "['08.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31BdiRuVllL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x300 at 0x7E53BD528070>\n",
      "175.30408888888888\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C+5WzuXOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C666C9A0>\n",
      "248.73976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C+5WzuXOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C7C40B50>\n",
      "248.73976\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C3Uybdh7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1266x1266 at 0x7E53BD397670>\n",
      "253.32389521549132\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C3Uybdh7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1266x1266 at 0x7E53BE739420>\n",
      "253.32389521549132\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C4TM0tL5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C42920>\n",
      "234.119508\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C5D5F9D9S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53D4A87520>\n",
      "251.405047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C5D5F9D9S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E54F00AEC80>\n",
      "251.405047\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C8QnlC+US.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53C7C42590>\n",
      "248.28168365552213\n",
      "['5.0 inch', '12.6 centimetre', '3.1 inch', '7.8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31C8QnlC+US.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BC9E15A0>\n",
      "248.28168365552213\n",
      "['5.0 inch', '12.6 centimetre', '3.1 inch', '7.8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CRyJdjbPL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x427 at 0x7E54E5F5F8E0>\n",
      "213.0805386416862\n",
      "['226.7 gram']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CUWR5Vl6L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BD5D4F70>\n",
      "245.29316898096582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.59 inch', '1.5 centimetre', '0.78 inch', '2 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CUWR5Vl6L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53D4AF6D10>\n",
      "245.29316898096582\n",
      "['0.59 inch', '1.5 centimetre', '0.78 inch', '2 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CUkGWrSHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=323x500 at 0x7E53C666F400>\n",
      "170.28011145510837\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CXR2nI5xL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77EBCA0>\n",
      "239.264752\n",
      "['800 pound']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Cst7vLIAL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x430 at 0x7E53BC9E2560>\n",
      "237.96791627906975\n",
      "['80 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CuqYq6tSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD397670>\n",
      "242.81313514709473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CuqYq6tSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C666E890>\n",
      "242.81313514709473\n",
      "['35 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CuqYq6tSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BE739360>\n",
      "242.81313514709473\n",
      "['35 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CwBXxyu4L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=271x248 at 0x7E53BD338730>\n",
      "215.20338352577073\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31CwvpacgHS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53BD4EE320>\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Czfm+KFwL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E5412C4C340>\n",
      "245.74755191802979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['64 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Czfm+KFwL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54132A1900>\n",
      "245.74755191802979\n",
      "['64 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31D+TJtQ3tL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=89x500 at 0x7E53BD396B90>\n",
      "209.13669662921347\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31D0mqjJbmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53C77D5F30>\n",
      "253.4671246872641\n",
      "['1.5 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31D0mqjJbmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53C77EBA00>\n",
      "253.4671246872641\n",
      "['1.5 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DGWuERDrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53BD4EF8E0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DJ8wTJNML.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=347x500 at 0x7E53BE75D870>\n",
      "212.45077809798272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DKMfOhB4L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54132A1900>\n",
      "219.303636\n",
      "['12 volt', '13.7 centimetre', '5.39 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DKMfOhB4L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E5412C4C4F0>\n",
      "219.303636\n",
      "['12 volt', '13.7 centimetre', '5.39 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DOXzkNKSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53C7C40C40>\n",
      "249.28778786823912\n",
      "['4.7 inch', '12 centimetre', '2.4 inch', '6.1 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DOXzkNKSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BD528DF0>\n",
      "249.28778786823912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.7 inch', '12 centimetre', '2.4 inch', '6.1 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DOXzkNKSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BD397670>\n",
      "249.28778786823912\n",
      "['4.7 inch', '12 centimetre', '2.4 inch', '6.1 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DOqLer9YL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C77D7400>\n",
      "250.044472\n",
      "['60 centimetre', '9 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DOvGqtL5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7E53C666E890>\n",
      "180.9277117117117\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DTUHgs+EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77EBC10>\n",
      "202.598856\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DTUHgs+EL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D4D90>\n",
      "202.598856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DThunqDhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BE75D330>\n",
      "232.590677\n",
      "['14 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DThunqDhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E5412C4C340>\n",
      "232.590677\n",
      "['14 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Dbs085g7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x119 at 0x7E53BD528FA0>\n",
      "100.53312605042017\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Dcdu1QcDL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x415 at 0x7E5412C4CD60>\n",
      "178.338\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DmuoP26RL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=192x468 at 0x7E54132A3760>\n",
      "230.12380920584044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DmuvUrq-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD5280D0>\n",
      "246.59321689605713\n",
      "['100 centimetre', '40 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DmuvUrq-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53D4B2F760>\n",
      "246.59321689605713\n",
      "['100 centimetre', '40 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DvN4cwQUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C666F400>\n",
      "245.459736\n",
      "['11.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DvN4cwQUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C7C42470>\n",
      "245.459736\n",
      "['11.5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DvN4cwQUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD5D6EF0>\n",
      "245.459736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31DwFD7WLrL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x387 at 0x7E53BC99CF70>\n",
      "219.07345219638242\n",
      "['12 pound']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31E0jB22--L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=333x500 at 0x7E5412C4D1E0>\n",
      "218.2472972972973\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31E2Za-l0aL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x667 at 0x7E54E5F5F160>\n",
      "205.1694872563718\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31E2Za-l0aL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x667 at 0x7E53C7C424A0>\n",
      "205.1694872563718\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31E2Za-l0aL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x667 at 0x7E53BD5D4E50>\n",
      "205.1694872563718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31E4X+OlLaL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=159x500 at 0x7E53BD528070>\n",
      "153.98061635220125\n",
      "['3 metre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31E6+IKauhL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x328 at 0x7E5412C4C4F0>\n",
      "207.64303658536585\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EA580F0XS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C77D7400>\n",
      "190.10839\n",
      "['0 centimetre', '20 centimetre', '120 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EALe-kFOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1089x1089 at 0x7E53D4B2FD00>\n",
      "252.03657241924208\n",
      "['7.9 centimetre', '22.2 centimetre', '7.1 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EALe-kFOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1089x1089 at 0x7E53BD6D3760>\n",
      "252.03657241924208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.9 centimetre', '22.2 centimetre', '7.1 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EES5Hi6CL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=483x356 at 0x7E54F00AF8B0>\n",
      "168.65457580198665\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EES5Hi6CL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=483x356 at 0x7E53C77E9A80>\n",
      "168.65457580198665\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EIyTViitL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x310 at 0x7E53BD396B90>\n",
      "210.34587096774194\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EM4A8ItRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BD338130>\n",
      "215.30009602194787\n",
      "['5 centimetre', '15 kilogram']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EM4A8ItRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E5412C4CD60>\n",
      "215.30009602194787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5 centimetre', '15 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EM4A8ItRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E54138BAD70>\n",
      "215.30009602194787\n",
      "['5 centimetre', '15 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EQXX2AigL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x496 at 0x7E53BD528130>\n",
      "218.49649596774194\n",
      "['148 centimetre', '109 centimetre', '40 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31ESGvgb7nL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD338100>\n",
      "238.24835205078125\n",
      "['290.5 millimetre', '135 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EX9Bfz9RL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C42920>\n",
      "237.823656\n",
      "['5 kilogram', '32 centimetre', '31 centimetre', '5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EX9Bfz9RL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D64D0>\n",
      "237.823656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5 kilogram', '32 centimetre', '31 centimetre', '5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EX9Bfz9RL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD516140>\n",
      "237.823656\n",
      "['5 kilogram', '32 centimetre', '31 centimetre', '5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EXLx184gL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C666F400>\n",
      "189.64136\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Efo1-SdqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BD528F10>\n",
      "252.72892466275903\n",
      "['2.2 inch', '5.5 centimetre', '8.3 inch', '21.0 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Efo1-SdqL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BD5D5030>\n",
      "252.72892466275903\n",
      "['2.2 inch', '5.5 centimetre', '8.3 inch', '21.0 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EhbdBcSRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=195x500 at 0x7E53BD528070>\n",
      "219.52875897435896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EvISViE7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E53D4A87520>\n",
      "119.17106666666666\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31EvISViE7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E53C77D42B0>\n",
      "119.17106666666666\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Ewj0PXNdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53C666D6C0>\n",
      "238.4596\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Ewj0PXNdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD33A0E0>\n",
      "238.4596\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Ewj0PXNdL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53C77EBCA0>\n",
      "238.4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31F+TvJigZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=426x500 at 0x7E53C666E890>\n",
      "221.59677464788732\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FA-kVKufL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53D4B2FB20>\n",
      "234.704301\n",
      "['11 centimetre', '7 centimetre', '7 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FCBht4h-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E54E5F5FA30>\n",
      "251.20555680913392\n",
      "['1.3 inch', '3.3 centimetre', '3.14 inch', '8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FCBht4h-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53D49BDAB0>\n",
      "251.20555680913392\n",
      "['1.3 inch', '3.3 centimetre', '3.14 inch', '8 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FENdaQpaL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD5D5030>\n",
      "245.6642723083496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['300 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FEqYvWC+S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C77EBCA0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FG7liSrFS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C666EC80>\n",
      "244.350387\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FG7liSrFS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C7C413F0>\n",
      "244.350387\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FSOnHzONL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BC9E0280>\n",
      "251.65440162372218\n",
      "['3.9 inch', '10 centimetre', '3.1 inch', '8 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FSOnHzONL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53D4A87520>\n",
      "251.65440162372218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.9 inch', '10 centimetre', '3.1 inch', '8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FTfRTgQHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x188 at 0x7E5412C4C100>\n",
      "41.44140425531915\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FW4wk2iyL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1322x353 at 0x7E53BD528DF0>\n",
      "240.31275473250676\n",
      "['10 centimetre', '20 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FW4wk2iyL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1322x353 at 0x7E53BD515EA0>\n",
      "240.31275473250676\n",
      "['10 centimetre', '20 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FXdO0GMRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BE739360>\n",
      "251.216935\n",
      "['144 millimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FXdO0GMRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BC9E27A0>\n",
      "251.216935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['144 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fch26gY7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x409 at 0x7E53BD5D50F0>\n",
      "128.04022004889976\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fh8XDXKmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC9E27A0>\n",
      "207.351024\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fh8XDXKmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E5412C4CD60>\n",
      "207.351024\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fh8XDXKmL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC9E37C0>\n",
      "207.351024\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fmc5aFJ3L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD656A40>\n",
      "133.80456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fmc5aFJ3L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD513F10>\n",
      "133.80456\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fr-EuWQcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=299x389 at 0x7E53BE75D870>\n",
      "211.74772807387092\n",
      "['25 millimetre', '20 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Fr-EuWQcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=299x389 at 0x7E53C666F9A0>\n",
      "211.74772807387092\n",
      "['25 millimetre', '20 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31FwzRkbbVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1050x800 at 0x7E53BD5D5030>\n",
      "251.15500833333334\n",
      "['52 centimetre', '28 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31G1y-GxcEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E54E5F5F8E0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31G28N+HgKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD33A0E0>\n",
      "174.63364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31G7epMfOJL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1000x1000 at 0x7E53C7C41480>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31G9bxJzX1L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD514070>\n",
      "246.84682083129883\n",
      "['120 centimetre', '30 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GBPN94J4L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54F00AD1E0>\n",
      "246.13669681549072\n",
      "['3 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GD-sqjvfL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E5412C4C5E0>\n",
      "243.66807010817797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.14 inch', '8 centimetre', '3.74 inch', '9.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GD-sqjvfL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53D4B2F9D0>\n",
      "243.66807010817797\n",
      "['3.14 inch', '8 centimetre', '3.74 inch', '9.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GGjka5fcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1004x1004 at 0x7E53BD514070>\n",
      "249.49013805336423\n",
      "['6.29 inch', '16 centimetre', '8.26 inch', '21 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GGjka5fcL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1004x1004 at 0x7E53BD528BB0>\n",
      "249.49013805336423\n",
      "['6.29 inch', '16 centimetre', '8.26 inch', '21 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GKAhbIN8L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E5412C4C340>\n",
      "204.88961505889893\n",
      "['60 centimetre', '6 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GKAhbIN8L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD6561A0>\n",
      "204.88961505889893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60 centimetre', '6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GKLavjhUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BE739360>\n",
      "249.92445216049381\n",
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GKLavjhUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BD656320>\n",
      "249.92445216049381\n",
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GKLavjhUL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53BD33A0E0>\n",
      "249.92445216049381\n",
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GNqESSmKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D6F20>\n",
      "240.606636\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GNqESSmKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD513F10>\n",
      "240.606636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GO0eUnE7L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C414E0>\n",
      "223.764156\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GWCSzvXfL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=320x320 at 0x7E53BD5D62F0>\n",
      "203.858154296875\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GcK11qXXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=380x500 at 0x7E53BD338130>\n",
      "216.81134210526315\n",
      "['2447248 ton']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GmydQCkiS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53C7C40370>\n",
      "251.68098098525957\n",
      "['9 inch', '23 centimetre', '15.35 inch', '39 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GmydQCkiS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E5412C4C5E0>\n",
      "251.68098098525957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9 inch', '23 centimetre', '15.35 inch', '39 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GoXwn1aEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x163 at 0x7E53D4B2FFA0>\n",
      "240.1438282208589\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GoXwn1aEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x163 at 0x7E5412C4C4F0>\n",
      "240.1438282208589\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GoXwn1aEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x163 at 0x7E53BD5D4E50>\n",
      "240.1438282208589\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GxLDza1BL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E5412C4D3F0>\n",
      "238.68634128570557\n",
      "['60 centimetre', '5 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GzBqi4wLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD516140>\n",
      "208.46168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GzBqi4wLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD528040>\n",
      "208.46168\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31GzBqi4wLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53C7C41FC0>\n",
      "208.46168\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31H-iAPesuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD5D50F0>\n",
      "233.139739\n",
      "['1 centimetre', '4.3 inch', '13 centimetre', '5.1 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31H1c8qO3yS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD528070>\n",
      "235.903072\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31H41OlQpUS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=419x500 at 0x7E53C77D42B0>\n",
      "194.2766539379475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31H8g7yOh1S.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=353x500 at 0x7E54E5F5FA30>\n",
      "222.37382436260623\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HApDlSQjS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD528F10>\n",
      "206.09059143066406\n",
      "['24 centimetre', '60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HBk40RLYL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C666EC80>\n",
      "250.7504587173462\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HJ1AfCIgL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53C77D5750>\n",
      "248.9618835733882\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HJ1AfCIgL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53C666CA90>\n",
      "248.9618835733882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HJ1AfCIgL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E54138BAD70>\n",
      "248.9618835733882\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HN4Cts-DL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1004x1004 at 0x7E53BC99E0B0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HN4Cts-DL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1004x1004 at 0x7E5412C4C100>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HN4Cts-DL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1004x1004 at 0x7E53C666D660>\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HOaPtWAGS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54132A1900>\n",
      "233.45409488677979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['36 centimetre', '80 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HOaPtWAGS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BF73CF70>\n",
      "233.45409488677979\n",
      "['36 centimetre', '80 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HU1reGu2L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x594 at 0x7E53C77D78E0>\n",
      "27.24540824915825\n",
      "['12 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HU1reGu2L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x594 at 0x7E53D4B2F9D0>\n",
      "27.24540824915825\n",
      "['12 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HU1reGu2L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x594 at 0x7E53C7C42920>\n",
      "27.24540824915825\n",
      "['12 millimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HVBTKNjBL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x500 at 0x7E53BD528DF0>\n",
      "224.374635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HVh9jcCuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD514070>\n",
      "250.8130623085877\n",
      "['6.37 inch', '16.18 centimetre', '1.41 inch', '3.6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HVh9jcCuL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53D4B2F880>\n",
      "250.8130623085877\n",
      "['6.37 inch', '16.18 centimetre', '1.41 inch', '3.6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HYQmLB4qL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5FA30>\n",
      "249.74364\n",
      "['6 inch', '7 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HYQmLB4qL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC9E33A0>\n",
      "249.74364\n",
      "['6 inch', '7 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HZLPLvS1L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD514070>\n",
      "245.226184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['109.5 centimetre', '4.8 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HatwLHPOL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=417x500 at 0x7E53C666E560>\n",
      "228.91094004796162\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HdbJNq5pL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53BD5D6DA0>\n",
      "252.87082847222223\n",
      "['12 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HdbJNq5pL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53C666C700>\n",
      "252.87082847222223\n",
      "['12 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Hgy69UfvS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4B2FB20>\n",
      "150.35122\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HhQIgtn2L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=421x500 at 0x7E53BD339F00>\n",
      "201.97614251781474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HkazRRetL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1032x532 at 0x7E53C7C40F70>\n",
      "242.06940862330245\n",
      "['9 centimetre', '44 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HkazRRetL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1032x532 at 0x7E53C77D5600>\n",
      "242.06940862330245\n",
      "['9 centimetre', '44 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HmJQwLPTL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53D4A87520>\n",
      "218.063712\n",
      "['7.0 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31HmJQwLPTL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BD5D7040>\n",
      "218.063712\n",
      "['7.0 inch']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Hy0RNu6lL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C7C40CD0>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Hy0RNu6lL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C7C40B50>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Hz3Wm0bVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C666E560>\n",
      "245.29722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31I2yf8JvVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1030x1030 at 0x7E53BD396B90>\n",
      "236.7156772551607\n",
      "['40 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31I6-eWiinL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x97 at 0x7E53BD397670>\n",
      "218.2838969072165\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31I6dyYENhS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BC99E800>\n",
      "207.699088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31I8-Y0a4KL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BC9E3670>\n",
      "253.326753616333\n",
      "['30 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31I8-Y0a4KL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53BD338370>\n",
      "253.326753616333\n",
      "['30 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IG-j-JjwL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C7C424A0>\n",
      "252.317401\n",
      "['20 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IIZrDt9nL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7E5412C4C340>\n",
      "226.31784\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IJu27VBVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54F00AECE0>\n",
      "229.19024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39.3 inch', '99.8 centimetre', '28.96 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IJu27VBVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53D4B2F6A0>\n",
      "229.19024\n",
      "['39.3 inch', '99.8 centimetre', '28.96 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31ILGfbqiGL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD396B90>\n",
      "245.693776\n",
      "['1360 metre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IVavGwvSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54E5F5EB30>\n",
      "247.07817363739014\n",
      "['67 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Ig7stJhHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53C666F400>\n",
      "252.12177912507187\n",
      "['3.5 inch', '9.0 centimetre', '3.9 inch', '10 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Ig7stJhHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BC99E800>\n",
      "252.12177912507187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.5 inch', '9.0 centimetre', '3.9 inch', '10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Ig7stJhHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BD5D4D00>\n",
      "252.12177912507187\n",
      "['3.5 inch', '9.0 centimetre', '3.9 inch', '10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IlI8j5OGL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53C7C42920>\n",
      "249.42388709492548\n",
      "['7.07 inch', '18 centimetre', '14.93 inch', '38 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IqIjyhMxL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53C77D78E0>\n",
      "246.89264523155367\n",
      "['5.1 inch', '13.2 centimetre', '2 inch', '54 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31IqIjyhMxL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1005x1005 at 0x7E53BD5280D0>\n",
      "246.89264523155367\n",
      "['5.1 inch', '13.2 centimetre', '2 inch', '54 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31J6aKJ4NkS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD33A0E0>\n",
      "243.76993346978009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.5 inch', '2 centimetre', '2.1 inch', '5.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31J6aKJ4NkS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53BD513F10>\n",
      "243.76993346978009\n",
      "['5.5 inch', '2 centimetre', '2.1 inch', '5.5 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31J8iFws4sS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x400 at 0x7E53BC9E2D10>\n",
      "42.07359\n",
      "['8 centimetre', '150 gram', '4 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31JAETfPJDL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=225x225 at 0x7E53C7C40370>\n",
      "198.9420049382716\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31JKDnYHPvL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53BD528DF0>\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31JVaJ+Ks6L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E54E5F5FA30>\n",
      "232.204084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31JkXky0yvL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=819x1157 at 0x7E53C666DC30>\n",
      "247.5587468327313\n",
      "['60 centimetre', '80 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31JogsMfUiL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D6F20>\n",
      "224.411928\n",
      "['115.6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31JqJNDVc-L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x7E5412C4CA90>\n",
      "207.157575\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31K25OxgecL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53C7C42E90>\n",
      "249.59091\n",
      "['594 millimetre', '841 millimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KCW7EbmnL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=380x474 at 0x7E5412C4CA90>\n",
      "223.0734232733733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KGcyUuuoL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BC99F490>\n",
      "229.839989\n",
      "['29.7 centimetre', '21 millimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KPJ6pnp+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53D4B2F8B0>\n",
      "252.12168638269785\n",
      "['3.5 inch', '9.0 centimetre', '3.9 inch', '10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KPJ6pnp+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BD528F40>\n",
      "252.12168638269785\n",
      "['3.5 inch', '9.0 centimetre', '3.9 inch', '10 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KPsJeS-+L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x300 at 0x7E54132A3760>\n",
      "172.74933333333334\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KSeXa5EtL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=392x500 at 0x7E53BD33A0E0>\n",
      "243.2925255102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['96 centimetre', '40.64 centimetre', '33.02 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KSeXa5EtL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=392x500 at 0x7E53D4B2FD00>\n",
      "243.2925255102041\n",
      "['96 centimetre', '40.64 centimetre', '33.02 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KSeXa5EtL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=392x500 at 0x7E53C7C40DF0>\n",
      "243.2925255102041\n",
      "['96 centimetre', '40.64 centimetre', '33.02 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KVgtejelL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E5412C4C4F0>\n",
      "152.322136\n",
      "['12 volt']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KjEfi5nKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C77D6FE0>\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KjEfi5nKL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1024x1024 at 0x7E53C77D5750>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KlXBXzjXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E53BE75D870>\n",
      "251.09658944938718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9.8 inch', '25 centimetre', '5.9 inch', '15 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KlXBXzjXL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1006x1006 at 0x7E5412C4CD60>\n",
      "251.09658944938718\n",
      "['9.8 inch', '25 centimetre', '5.9 inch', '15 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KnFDzIaZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x112 at 0x7E53BD395420>\n",
      "195.71655357142856\n",
      "['400 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KnWMQYaRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53C7C43E80>\n",
      "243.29643472374502\n",
      "['3.4 inch', '8.6 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KnWMQYaRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1003x1003 at 0x7E53C77E98A0>\n",
      "243.29643472374502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.4 inch', '8.6 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KogrDVMSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E5519F88A00>\n",
      "248.36450274348422\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KogrDVMSL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7E53D4B2FB20>\n",
      "248.36450274348422\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31KunvSIUEL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1007x1007 at 0x7E53BD528FA0>\n",
      "251.03127758126087\n",
      "['2.3 inch', '6 centimetre', '2.3 inch', '2.3 inch']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Kx4J470RL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C401C0>\n",
      "219.66258\n",
      "['60 centimetre', '23.6 inch', '25 kilogram']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31L3YQLwF3L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=192x500 at 0x7E53BD5D4F70>\n",
      "145.22452083333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31L5f9HtrRL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x494 at 0x7E53C666EC80>\n",
      "212.2804979757085\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LAzzOrUkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1005x1005 at 0x7E53BD5D4E20>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LAzzOrUkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=1005x1005 at 0x7E53BC99E800>\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LBAhwrXyS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x1000 at 0x7E53BD5280D0>\n",
      "163.924346\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LD1aDwt5L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD4EE320>\n",
      "217.794924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LF8o3DjTL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=368x500 at 0x7E53C77EBCA0>\n",
      "223.26657608695652\n",
      "['33 centimetre', '8 foot', '3 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LL+eDCmwL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=350x233 at 0x7E53BD4EF8E0>\n",
      "182.4139791538933\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LNekHaVSS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77D4310>\n",
      "235.430276\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LNnSV4ssL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53BD5D6DA0>\n",
      "252.75144166666666\n",
      "['10 centimetre', '16 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LNnSV4ssL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1200 at 0x7E53D4B2FB20>\n",
      "252.75144166666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 centimetre', '16 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LOSIlyWLL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x382 at 0x7E53BD514070>\n",
      "243.5732617801047\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LXW+WymkL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x394 at 0x7E53BD397670>\n",
      "165.2361269035533\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LYuCcf6bL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x195 at 0x7E5412C4D1E0>\n",
      "232.74102564102563\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Lahs4a9SL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7E53BE75D870>\n",
      "232.779987987988\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LdY2um+OL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7E53BC9E0280>\n",
      "211.23397333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LeiIQqy4L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x185 at 0x7E54E5F5F220>\n",
      "240.1220864864865\n",
      "['3 kilogram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Lfi-0r4GL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C77D78E0>\n",
      "234.701884\n",
      "['19 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31Lfi-0r4GL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53C7C401C0>\n",
      "234.701884\n",
      "['19 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LmviTSuzS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E53C666C9A0>\n",
      "242.32349967956543\n",
      "['60 centimetre']\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LmviTSuzS.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024 at 0x7E54F00AE8F0>\n",
      "242.32349967956543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60 centimetre']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LrSRISE0L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x364 at 0x7E53C77D5780>\n",
      "201.39872527472528\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LrSRISE0L.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x364 at 0x7E53BD338100>\n",
      "201.39872527472528\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LwkMqi+DL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x453 at 0x7E53BD656A40>\n",
      "171.67427814569535\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LwkMqi+DL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x453 at 0x7E53D4B2F640>\n",
      "171.67427814569535\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31LwkMqi+DL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x453 at 0x7E53BD5D5030>\n",
      "171.67427814569535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31MG0yf59ZL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=393x500 at 0x7E53BE75D330>\n",
      "173.19065648854962\n",
      "['100 gram']\n",
      "Processing Image: https://m.media-amazon.com/images/I/31MLB7TWBVL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=138x500 at 0x7E53D4B2F9D0>\n",
      "185.27195652173913\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31MRd8GBmjL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=607x614 at 0x7E53C77D7EE0>\n",
      "201.4697986036952\n",
      "[]\n",
      "Processing Image: https://m.media-amazon.com/images/I/31MSh7g6jHL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7E53BD5D4E20>\n",
      "232.377276\n",
      "[]\n",
      "Appended results to /kaggle/working/output_easyocr.csv\n",
      "Processing Image: https://m.media-amazon.com/images/I/31MUroBHxlL.jpg\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x156 at 0x7E53D4B2FE50>\n",
      "248.48726923076924\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Run OCR on each image link\n",
    "for index, row in data.iterrows():\n",
    "    image_link = row['image_link']\n",
    "    entity_name = row['entity_name']\n",
    "\n",
    "    print(f\"Processing Image: {image_link}\")\n",
    "\n",
    "    # Load the image from the URL\n",
    "    image = load_image_from_url(image_link)\n",
    "    print(image)\n",
    "\n",
    "    if image:\n",
    "        try:\n",
    "            # Convert PIL image to an OpenCV image (numpy array)\n",
    "            image_np = np.array(image)\n",
    "\n",
    "            # Pre-processing Images\n",
    "            grayscale_image = inversion_check(image_np)\n",
    "            sharpened_image = sharpen_image(grayscale_image)\n",
    "\n",
    "            # Perform OCR\n",
    "            extracted_text = easyocr_model(sharpened_image)\n",
    "        except Exception as e:\n",
    "            extracted_text = f\"Error: {e}\"\n",
    "    else:\n",
    "        extracted_text = \"Image not available\"\n",
    "\n",
    "    extract, num, units = convert_to_full_unit(extracted_text)\n",
    "    print(extract)\n",
    "    categorized_values = categorize_values(num, units)\n",
    "    final_val = get_entity_value(entity_name, categorized_values)\n",
    "\n",
    "    # Append the result to the list\n",
    "    results.append({\n",
    "        'index_id': index,\n",
    "        'entity_name': entity_name,\n",
    "        'extracted_text': final_val\n",
    "    })\n",
    "    # Append results to the CSV every batch_size iterations\n",
    "    if (index + 1) % batch_size == 0 or index == len(data) - 1:\n",
    "        # Convert the current batch of results into a DataFrame\n",
    "        output_df = pd.DataFrame(results)\n",
    "\n",
    "        # Append to CSV if it exists, otherwise create it\n",
    "        if not os.path.isfile(output_csv):\n",
    "            output_df.to_csv(output_csv, index=False, columns=['index_id', 'prediction'])\n",
    "        else:\n",
    "            output_df.to_csv(output_csv, mode='a', header=False, index=False, columns=['index_id', 'extracted_text'])\n",
    "\n",
    "        # Clear the results list after writing to CSV\n",
    "        results = []\n",
    "\n",
    "        print(f\"Appended results to {output_csv}\")\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "# output_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save the results to a new CSV file\n",
    "# output_df.to_csv(output_csv, index=False, columns=[\n",
    "#                  'index_id', 'entity_name', 'extracted_text'])\n",
    "\n",
    "print(f\"Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5706692,
     "sourceId": 9401046,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
